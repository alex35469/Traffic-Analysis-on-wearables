{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-run identificaiton\n",
    "\n",
    "<a id='tc'></a>\n",
    "## Table of content\n",
    "\n",
    "**PART I** - [Setup](#setup)\n",
    "1. [imports](#imports)\n",
    "2. [helpers](#helpers)\n",
    "3. [evaluate function](#evaluate)\n",
    "4. [build per action capture model](#build-per-action-capture-model)\n",
    "\n",
    "2. [sliding time window](#stw)\n",
    "    1. [implementation](#implementation_stw)\n",
    "    2. [Training](#evaluation_stw)\n",
    "        - No training, output simply majority voting\n",
    "        - Train on per-action capture: perform data augmentation (cut corp the data) labeled as 1. etc...and use NoApp NoAction labeled as 0 (maybe use same model as )\n",
    "        - Train on longrun capture with probabilities output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## PART I - Setup\n",
    "[table of content](#tc)\n",
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "from build_datasets import *\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='helpers'></a>\n",
    "## Helpers\n",
    "[Table of Content](#tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Capture time serie\n",
    "\n",
    "all_columns = set()\n",
    "def extract_columns(dataset_file):\n",
    "    all_columns = set()\n",
    "\n",
    "    with open(dataset_file, \"r\") as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "        for i, line in enumerate(csv_reader):\n",
    "            all_columns.update(line)\n",
    "            return all_columns\n",
    "\n",
    "\n",
    "def new_packet(columns):\n",
    "    packet = dict()\n",
    "    for column in columns:\n",
    "        packet[column] = \"\"\n",
    "\n",
    "    return packet\n",
    "\n",
    "\n",
    "def read_file(dataset_file, columns):\n",
    "    \"\"\"\n",
    "    Reads a .csv file and puts its raw contents in packet_store[dataset_file]\n",
    "    \"\"\"\n",
    "    ID_COLUMN = \"Packet #\"\n",
    "    dataset_packet_store = dict() # packetID => packets\n",
    "    headers = []\n",
    "    with open(dataset_file, \"r\") as file:\n",
    "        reader = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "\n",
    "        for i, line in enumerate(reader):\n",
    "            if i == 0:\n",
    "                headers = line\n",
    "                continue\n",
    "\n",
    "            packet = new_packet(columns)\n",
    "\n",
    "            for j, item in enumerate(line):\n",
    "                key = headers[j]\n",
    "                val = item\n",
    "\n",
    "                if key not in packet:\n",
    "                    print(packet)\n",
    "                    print(\"Fatal: column '{}' not found in packet; all_columns is {}\".format(key, columns))\n",
    "                    sys.exit(1)\n",
    "                packet[key] = val\n",
    "\n",
    "            packet_id = toInt(packet[ID_COLUMN].replace('\\'', ''))\n",
    "            if packet_id not in dataset_packet_store:\n",
    "                dataset_packet_store[packet_id] = []\n",
    "\n",
    "            dataset_packet_store[packet_id].append(packet)\n",
    "\n",
    "    return dataset_packet_store\n",
    "\n",
    "def extract_payload_length(payload_string, default=0):\n",
    "    payload_string = payload_string.strip()\n",
    "    if payload_string == \"\" or \"No data\" in payload_string:\n",
    "        return default\n",
    "    parts = payload_string.split(' ')\n",
    "    return toInt(parts[0])\n",
    "\n",
    "def packet_store_cleanup(packets): #dataset_packet_store is packetID => packets\n",
    "    for packet_id in packets:\n",
    "        layers = packets[packet_id]\n",
    "        for layer in layers:\n",
    "            layer[ID_COLUMN] = toInt(layer[ID_COLUMN])\n",
    "            layer[\"Time\"] = toFloat(layer[\"Time\"], default=-1)\n",
    "            layer[\"Time delta\"] = toFloat(layer[\"Time delta\"], default=-1)\n",
    "            layer[\"PayloadLength\"] = extract_payload_length(layer[\"Payload\"], default=0)\n",
    "            layer[\"PayloadRaw\"] = extract_payload_bytes(layer[\"Payload\"])\n",
    "    return packets\n",
    "\n",
    "\n",
    "def packets_to_timesize_tuples(packets):\n",
    "    global master\n",
    "    xy = dict(xs=[], ys=[])\n",
    "    packets_ids = list(packets.keys())\n",
    "    packets_ids.sort(reverse=False)\n",
    "\n",
    "    # Ensure that the direction stays the same even if HUAWEI Watch becomes master\n",
    "\n",
    "\n",
    "    for packet_id in packets_ids:\n",
    "        for layer in packets[packet_id]:\n",
    "            master = extract_master(layer[\"Communication\"])\n",
    "            if master in POSSIBLE_MASTERS:\n",
    "                direction = 1\n",
    "            else:\n",
    "                print(\"WARNING master not in Possible masters: '\" + master + \"'\")\n",
    "                print(layer[\"Communication\"])\n",
    "                direction = -1\n",
    "\n",
    "            if not \"master\" in layer['Transmitter'].lower():\n",
    "                direction *= -1\n",
    "            xy['xs'].append(float(layer['Time']))\n",
    "            xy['ys'].append(direction * int(layer['PayloadLength']))\n",
    "    return xy\n",
    "\n",
    "\n",
    "\n",
    "def merge_actions_in_app(events, to_merge):\n",
    "    for actions in to_merge:\n",
    "        events = merge_action_in_app(events, actions)\n",
    "    return events\n",
    "\n",
    "\n",
    "def merge_action_in_app(events, to_merge, separate_watch=True, maximum_level=None): # TODO separate watch\n",
    "    \"\"\"to_merge is of the form [app_feature_x1, app_feature_x2...]\n",
    "    Cannot merge across apps\n",
    "    \"\"\"\n",
    "    ## TODO: Make sure merge and \n",
    "    app = to_merge[0].split(\"_\")[0]\n",
    "    events_out = copy.deepcopy(events)\n",
    "    to_merge_action_set = set([f.split(\"_\")[1] for f in to_merge])\n",
    "    print(\"to_merge_action_set = \", to_merge_action_set)\n",
    "    for w in events:\n",
    "        for appli in events[w]:\n",
    "            if appli != app:\n",
    "                continue\n",
    "            merged_actions = []\n",
    "            labeled_actions = \"\"\n",
    "            for action in events[w][app]:\n",
    "                if action in to_merge_action_set:\n",
    "                    labeled_actions += action\n",
    "                    merged_actions += events[w][app][action]\n",
    "                    del events_out[w][app][action]\n",
    "            events_out[w][app][labeled_actions] = merged_actions\n",
    "    return events_out\n",
    "\n",
    "\n",
    "def discard_actions(source_files, to_discard):\n",
    "    sf_new = []\n",
    "    for f in source_files:\n",
    "        _in = False\n",
    "        for df in to_discard:\n",
    "            if df in f:\n",
    "                _in = True\n",
    "        if not _in:\n",
    "            sf_new.append(f)\n",
    "    return sf_new\n",
    "\n",
    "\n",
    "def build_features_labels_dataset(events, adversary_capture_duration=-1, unique_from=46, unique_to=1006):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for device in events:\n",
    "        for app in events[device]:\n",
    "            for action in events[device][app]:\n",
    "                label = app + \"_\" + action\n",
    "                for event in events[device][app][action]:\n",
    "                    features_dict = extract_features(event, adversary_capture_duration, unique_from, unique_to)\n",
    "                    features = list(features_dict.values())\n",
    "                    data.append(features)\n",
    "                    labels.append(label)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "\n",
    "def delete_different_action_across_watch(events):\n",
    "        # Create common action set if multiple watches\n",
    "    intersection_set = set()\n",
    "    for i, w in enumerate(events):\n",
    "        all_action = []\n",
    "        for app in events[w]:\n",
    "            actions = set(events[w][app].keys())\n",
    "            all_action += [app + \"_\" + act for act in actions]\n",
    "        if i == 0:\n",
    "            intersection_set = set(all_action)\n",
    "        else:\n",
    "            intersection_set = intersection_set.intersection(set(all_action))\n",
    "    \n",
    "    events_copy = copy.deepcopy(events)\n",
    "    # Delete not common action from dictionnary\n",
    "    for device in events_copy:\n",
    "        for app in events_copy[device]:\n",
    "            for action in events_copy[device][app]:\n",
    "                if app + \"_\" + action not in intersection_set:\n",
    "                    del events[device][app][action]\n",
    "    return events\n",
    "\n",
    "\n",
    "def equilibrate_events_across_apps_and_watch(events):\n",
    "    \"\"\"\n",
    "    Equilibrate the events by identifing the minimum number of samples per class\n",
    "    and discarding Randomly the extra samples present in the oder classes. \n",
    "    If there are multiple watchs, only the common application are kept\n",
    "\n",
    "    Parameters: \n",
    "        events (dict[watch][app][action] -> event): dataset \n",
    "\n",
    "    Returns: \n",
    "        events (dict[watch][app][action] -> event): equilibrate dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    events = delete_different_action_across_watch(events)\n",
    "    \n",
    "    # Find minimum samples \n",
    "    counts = dict()\n",
    "    for device in events:\n",
    "        for app in events[device]:\n",
    "            for action in events[device][app]:\n",
    "                counts[device + \"_\" + app +\"_\" + action] = 0\n",
    "            for action in events[device][app]:\n",
    "                counts[device + \"_\" + app + \"_\" + action] += len(events[device][app][action])\n",
    "\n",
    "    if len(counts.values())== 0:\n",
    "        return events\n",
    "\n",
    "\n",
    "    nb_samples_per_cat = min(counts.values())\n",
    "\n",
    "    events_out = dict()\n",
    "\n",
    "    # remove everything above the min across devices\n",
    "    for device in events:\n",
    "        for app in events[device]:\n",
    "\n",
    "            for action in events[device][app]:\n",
    "\n",
    "                if not device in events_out:\n",
    "                    events_out[device] = dict()\n",
    "                if not app in events_out[device]:\n",
    "                    events_out[device][app] = dict()\n",
    "                if not action in events_out[device][app]:\n",
    "                    events_out[device][app][action] = random.sample(events[device][app][action], k=nb_samples_per_cat)\n",
    "\n",
    "    counts = dict()\n",
    "    for device in events_out:\n",
    "        for app in events_out[device]:\n",
    "            if not app in counts:\n",
    "                counts[app] = 0\n",
    "            for action in events_out[device][app]:\n",
    "                counts[app] += len(events_out[device][app][action])\n",
    "\n",
    "    return events_out, nb_samples_per_cat\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(xy, capture_duration_does_nothing=0, unique_from=46, unique_to=1006): # dataset is {'xs': [packet1, packet2,...], 'ys': [packet1, packet2,...]} where x is time and y is size\n",
    "    xs = xy['xs']\n",
    "    ys = xy['ys']\n",
    "    f = dict()\n",
    "\n",
    "    def take(arr, n=30):\n",
    "        if len(arr) > n:\n",
    "            return arr[:30]\n",
    "        return arr\n",
    "\n",
    "    def stats(key, data):\n",
    "        if len(data) == 0:\n",
    "            data=[-1]\n",
    "        f['min_'+key] = np.min(data)\n",
    "        f['mean_'+key] = np.mean(data)\n",
    "        f['max_'+key] = np.max(data)\n",
    "        f['count_'+key] = len(data)\n",
    "        f['std_'+key] = np.std(data)\n",
    "        f['kurtosis_'+key] = kurtosis(data)\n",
    "\n",
    "\n",
    "\n",
    "    # general statistics\n",
    "    stats(\"non_null\", [abs(y) for y in ys if y != 0])\n",
    "    stats(\"outgoing\", [abs(y) for y in ys if y > 0])\n",
    "    stats(\"incoming\", [abs(y) for y in ys if y < 0])\n",
    "    stats(\"outgoing_30\", [abs(y) for y in take(ys) if y > 0])\n",
    "    stats(\"incoming_30\", [abs(y) for y in take(ys) if y < 0])\n",
    "\n",
    "    # f[\"total_payload\"] = sum([abs(y) for y in ys])\n",
    "\n",
    "    # statistics about timings\n",
    "    x_deltas = []\n",
    "    i = 1\n",
    "    while i<len(xs):\n",
    "        x_deltas.append(xs[i]-xs[i-1])\n",
    "        i += 1\n",
    "\n",
    "    stats(\"x_deltas\", x_deltas)\n",
    "    stats(\"x_deltas_30\", take(x_deltas))\n",
    "\n",
    "    # bursts\n",
    "\n",
    "    # unique packet lengths [Liberatore and Levine; Herrmann et al.]\n",
    "    lengths = dict()\n",
    "    for i in range(unique_from, unique_to):\n",
    "        lengths[str(i)] = 0\n",
    "    for y in ys:\n",
    "        if str(abs(y)) in lengths:\n",
    "            lengths[str(abs(y))] += 1\n",
    "\n",
    "    lengths_array = list(lengths.values())\n",
    "    stats(\"unique_lengths\", lengths_array)\n",
    "    for l in lengths:\n",
    "        f['unique_lengths_'+str(l)] = lengths[l]\n",
    "        \n",
    "    return f\n",
    "\n",
    "\n",
    "def filter_by_length(events, minimum_payload=200, ratio_app_not_satisfing_minimum_payload_length=0.25, printInfo = False):\n",
    "    results = copy.deepcopy(events)\n",
    "    for watch in events:\n",
    "        for app in events[watch]:\n",
    "            for action in events[watch][app]:\n",
    "                total_event = len(events[watch][app][action])\n",
    "                bellow_minimum_payload = 0\n",
    "                for sample in events[watch][app][action]:\n",
    "\n",
    "                    payload_length = sum([abs(s) for s in sample[\"ys\"]])\n",
    "                    if payload_length < minimum_payload:\n",
    "                        bellow_minimum_payload += 1\n",
    "\n",
    "                ratio_bellow = bellow_minimum_payload / total_event\n",
    "                if ratio_bellow > ratio_app_not_satisfing_minimum_payload_length:\n",
    "                    if printInfo:\n",
    "                        print(\"total_event: \", total_event, \" - bellow threshold: \", bellow_minimum_payload)\n",
    "                        print(app + \"_\" + action + \" removed\")\n",
    "                        print(\" ratio_below = \", ratio_bellow)\n",
    "                    del results[watch][app][action]\n",
    "\n",
    "            if len(results[watch][app]) == 0:\n",
    "                del results[watch][app]\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def count_print(events):\n",
    "    for d in events:\n",
    "        for app in events[d]:\n",
    "            for act in events[d][app]:\n",
    "                print(\"{}: {}_{} - {}\".format(d, app, act,  len(events[d][app][act])))\n",
    "\n",
    "                \n",
    "# Compute the mean over realisations\n",
    "def plot_acc_and_conf(n_samples, accuracies, repeat, title, xlabel, ylabel, fname, y_lim=None, RETURN_ACC=False, dpi=500):\n",
    "    n_samples = np.array(n_samples)\n",
    "    accuracies = np.array(accuracies)\n",
    "\n",
    "\n",
    "    n_samples_repr = n_samples.reshape((-1,repeat))[:,0]\n",
    "    accuracies_repr = accuracies.reshape((-1,repeat)) * 100\n",
    "\n",
    "    accuracies_avg = accuracies.reshape((-1,repeat)).mean(axis = 1)\n",
    "    if RETURN_ACC:\n",
    "        return n_samples_repr, accuracies_avg\n",
    "    \n",
    "    accuracies_conf = accuracies.reshape((-1,repeat)).std(axis = 1) * 2 \n",
    "\n",
    "    conf_upper = accuracies_avg + accuracies_conf\n",
    "    conf_lower = accuracies_avg - accuracies_conf\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(n_samples_repr, accuracies_avg, '-b', label='averaged accuracy')\n",
    "    ax.plot(n_samples_repr, conf_upper, '--r', label='95% confidence interval')\n",
    "    ax.plot(n_samples_repr, conf_lower, '--r')\n",
    "    plt.title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if y_lim is not None:\n",
    "        plt.ylim(y_lim[0], y_lim[1])\n",
    "    leg = ax.legend()\n",
    "    plt.savefig(\"./\"+fname, dpi=dpi)\n",
    "\n",
    "    \n",
    "    \n",
    "def extract_features(xy, capture_duration_does_nothing=0, unique_from=46, unique_to=1006): # dataset is {'xs': [packet1, packet2,...], 'ys': [packet1, packet2,...]} where x is time and y is size\n",
    "    xs = xy['xs']\n",
    "    ys = xy['ys']\n",
    "    f = dict()\n",
    "\n",
    "    def take(arr, n=30):\n",
    "        if len(arr) > n:\n",
    "            return arr[:30]\n",
    "        return arr\n",
    "\n",
    "    def stats(key, data):\n",
    "        if len(data) == 0:\n",
    "            data=[-1]\n",
    "        f['min_'+key] = np.min(data)\n",
    "        f['mean_'+key] = np.mean(data)\n",
    "        f['max_'+key] = np.max(data)\n",
    "        f['count_'+key] = len(data)\n",
    "        f['std_'+key] = np.std(data)\n",
    "        f['kurtosis_'+key] = kurtosis(data)\n",
    "\n",
    "\n",
    "\n",
    "    # general statistics\n",
    "    stats(\"non_null\", [abs(y) for y in ys if y != 0])\n",
    "    stats(\"outgoing\", [abs(y) for y in ys if y > 0])\n",
    "    stats(\"incoming\", [abs(y) for y in ys if y < 0])\n",
    "    stats(\"outgoing_30\", [abs(y) for y in take(ys) if y > 0])\n",
    "    stats(\"incoming_30\", [abs(y) for y in take(ys) if y < 0])\n",
    "\n",
    "    # f[\"total_payload\"] = sum([abs(y) for y in ys])\n",
    "\n",
    "    # statistics about timings\n",
    "    x_deltas = []\n",
    "    i = 1\n",
    "    while i<len(xs):\n",
    "        x_deltas.append(xs[i]-xs[i-1])\n",
    "        i += 1\n",
    "\n",
    "    stats(\"x_deltas\", x_deltas)\n",
    "    stats(\"x_deltas_30\", take(x_deltas))\n",
    "\n",
    "    # bursts\n",
    "\n",
    "    # unique packet lengths [Liberatore and Levine; Herrmann et al.]\n",
    "    lengths = dict()\n",
    "    for i in range(unique_from, unique_to):\n",
    "        lengths[str(i)] = 0\n",
    "    for y in ys:\n",
    "        if str(abs(y)) in lengths:\n",
    "            lengths[str(abs(y))] += 1\n",
    "\n",
    "    lengths_array = list(lengths.values())\n",
    "    stats(\"unique_lengths\", lengths_array)\n",
    "    for l in lengths:\n",
    "        f['unique_lengths_'+str(l)] = lengths[l]\n",
    "        \n",
    "    return f\n",
    "\n",
    "def get_all_actions(events):\n",
    "    all_actions = set()\n",
    "    for d in events:\n",
    "        for app in events[d]:\n",
    "            for act in events[d][app]:\n",
    "                all_actions.add(app+\"_\"+act)\n",
    "    return all_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate\"></a>\n",
    "### Evaluate\n",
    "[Table of Content](#tc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(DATA_PATH, DISCARDED_ACTION=[], TO_MERGE=[], EQUALIZATION=True,\n",
    "             REBUILD=False, TEST_PERCENTAGE=0.25, MINIMUM_PAYLOAD=200, SHUFFLE=False,\n",
    "             RATIO=0.25, N_SPLITS=50, N_ESTIMATOR=100, SEPARATE_WATCH=False,\n",
    "             PRINT_COUNT=False, PLOT_DIR=\"./plots/\", RETURN_PRED=False, RETURN_FILTIRED=False,\n",
    "             RETURN_EQUILIBRATE_EVENTS=False, RETURN_FEATURES_AND_LABELS=False):\n",
    "    \n",
    "    print(\"\\nimporting data...\")\n",
    "    sources_files = find_sources(DATA_PATH)\n",
    "\n",
    "\n",
    "    if len(DISCARDED_ACTION) != 0:\n",
    "        print(\"withdraw action to be discarded\")\n",
    "        sources_files = discard_actions(sources_files, DISCARDED_ACTION)\n",
    "\n",
    "\n",
    "    if REBUILD:\n",
    "        print(\"rebuilding dataset\")\n",
    "        rebuild_all_datasets(sources_files)\n",
    "\n",
    "    events, counts = cut_all_datasets_in_events(sources_files)\n",
    "\n",
    "    if len(TO_MERGE) != 0:\n",
    "        print(\"merging events\")\n",
    "        events = merge_actions_in_app(events, TO_MERGE)\n",
    "\n",
    "\n",
    "    print(\"filtering app that does not send traffic by their length\")\n",
    "    filtered_events = filter_by_length(events, minimum_payload=MINIMUM_PAYLOAD, ratio_app_not_satisfing_minimum_payload_length=RATIO)\n",
    "    \n",
    "    if RETURN_FILTIRED:\n",
    "        return filtered_events\n",
    "    \n",
    "    if PRINT_COUNT:\n",
    "        print(\"\\nclass event count\")\n",
    "        count_print(filtered_events)\n",
    "        print()\n",
    "\n",
    "    nb_samples_per_cat = \"not uniform\"\n",
    "    if EQUALIZATION:\n",
    "        print(\"dataset equalization per class\")\n",
    "        filtered_events, nb_samples_per_cat = equilibrate_events_across_apps_and_watch(filtered_events)\n",
    "        \n",
    "        if PRINT_COUNT:\n",
    "            print(\"\\nclass event count after equalization\")\n",
    "            count_print(filtered_events)\n",
    "            print()\n",
    "        if RETURN_EQUILIBRATE_EVENTS:\n",
    "            return filtered_events\n",
    "    \n",
    "    if SEPARATE_WATCH:\n",
    "        print(\"separate watch action\")\n",
    "        filtered_events = separate_watch(filtered_events)\n",
    "        if PRINT_COUNT:\n",
    "            print()\n",
    "            count_print(filtered_events)\n",
    "\n",
    "\n",
    "    print(\"building features and labels\")\n",
    "    X, y = build_features_labels_dataset(filtered_events)\n",
    "    if RETURN_FEATURES_AND_LABELS:\n",
    "        return X, y\n",
    "\n",
    "    # ## Accuracy with cross validation\n",
    "\n",
    "    print(\"building and training the model for cross validation \")\n",
    "    clf=RandomForestClassifier(n_estimators=N_ESTIMATOR, random_state=None)\n",
    "    shuf_split = ShuffleSplit(n_splits=N_SPLITS, test_size=0.25, random_state=None)\n",
    "    scores_shuffle = cross_val_score(clf, X, y, cv=shuf_split)\n",
    "    print(\"Random split cross-validation: Accuracy=%0.3f (+/- %0.2f). \" % (scores_shuffle.mean(), scores_shuffle.std() * 2))\n",
    "    eval_metric = \"cross-val radomSplit={} accRs={:.1f} +-{:.1f}% 95% conf interval\".format(N_SPLITS, scores_shuffle.mean() *100, scores_shuffle.std() * 2 * 100)\n",
    "\n",
    "    # ### Plotting the confusion matrix\n",
    "\n",
    "    print(\"building and training a model for confusion matrix\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=None)\n",
    "\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    if RETURN_PRED:\n",
    "        return y_test, y_pred\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy = \", accuracy)\n",
    "\n",
    "\n",
    "    title = \"Confusion matrix for {}acc={:0.2f} \".format(\"and \".join([f.replace(\"/\", \"_\") for f in DATA_PATH]), accuracy * 100)\n",
    "    title += eval_metric\n",
    "    title += \"test={}% minimum_payload={}B nb_samples={}\".format(int(TEST_PERCENTAGE * 100), MINIMUM_PAYLOAD, nb_samples_per_cat)\n",
    "    saved_title = title.replace(\".\", \"_\").replace(\" \", \"_\")\n",
    "    cm, _, _ = plot_confusion_matrix(y_test, y_pred, title= title, save = saved_title, PLOT_DIR=PLOT_DIR)\n",
    "\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build-per-action-capture-model'></a>\n",
    "## Preparation\n",
    "\n",
    "### Build per action capture model\n",
    "[Table of Content](#tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "importing data...\n",
      "filtering app that does not send traffic by their length\n",
      "dataset equalization per class\n",
      "building features and labels\n",
      "\n",
      "importing data...\n",
      "filtering app that does not send traffic by their length\n"
     ]
    }
   ],
   "source": [
    "# Choose the data to be included in the model\n",
    "DATA_PATH = [\"data/huawei/Endomondo-1/\", \"data/huawei/force-stop/\", \"data/huawei/DiabetesM-2/\",\n",
    "             \"data/huawei/DiabetesM-3/\", \"data/huawei/DiabetesM-4/\",\n",
    "             \"data/huawei/FoursquareCityGuide-1/\", \"data/huawei/HealthyRecipes-1/\",\n",
    "             \"data/huawei/Lifesum-1/\", \"data/huawei/Playstore-1/\", \"data/huawei/open-6/\"]\n",
    "\n",
    "# Extract features \n",
    "X, y = evaluate(DATA_PATH, RETURN_FEATURES_AND_LABELS=True)\n",
    "\n",
    "# Create and Train the model\n",
    "clf=RandomForestClassifier(n_estimators=200, random_state=None)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Get the set of all classes the classifier knows about\n",
    "events = evaluate(DATA_PATH, RETURN_FILTIRED=True)\n",
    "all_actions = get_all_actions(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='convert-longrun'></a>\n",
    "### Import data, ground-truth and checked ground-truth\n",
    "[Table of Content](#tc)\n",
    "\n",
    "\n",
    "- ***Data*** refers to the actual longrun captures \n",
    "\n",
    "- ***Ground-truth*** refers to the metadata that comes automatically with the longrun capture. It is a log file and contains information about which and when an action is performed since the capture's launch\n",
    "\n",
    "- ***Checked ground-truth*** refers to the manually checked ground-thruth. (Used to measure the discrepancy of the automation vs the manual checked. This discrepency is due to a delay between sending the command to performing an action and the actual traffic generated by this action).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_path(fs, filter_out_device = False):\n",
    "    f = fs[fs.rfind('/')+ 1:]\n",
    "    if filter_out_device:\n",
    "        f = f[f.rfind('_')+ 1:]\n",
    "    return f\n",
    "\n",
    "# Finds datasets recursively\n",
    "def find_sources(folders='./'):\n",
    "\n",
    "    if type(folders) is not list:\n",
    "        folders = [folders]\n",
    "\n",
    "    sources_files = []\n",
    "\n",
    "    for folder in folders:\n",
    "        files = glob.glob(folder + '*.csv', recursive=True)\n",
    "        for file in files:\n",
    "            ignore = False\n",
    "            for ignore_pattern in SOURCES_FILE_IGNORE:\n",
    "                if ignore_pattern in file:\n",
    "                    ignore = True\n",
    "            if not ignore:\n",
    "                sources_files.append(file.replace('./', ''))\n",
    "\n",
    "    return sorted(sources_files)\n",
    "\n",
    "def extract_fname(f):\n",
    "    return filter_out_path(f[:f.rfind(\".\")])\n",
    "\n",
    "def intersection_fname(files1, files2, print_missing=True):\n",
    "    \"Return the list of files names (without extension) that files1 containes and files2 contains\"\n",
    "    if len(files1) == 0 or len(files2) == 0:\n",
    "        print(\"WARNING: one or both dir. are empty\")\n",
    "        return []\n",
    "\n",
    "    extension1 = files1[0][files1[0].rfind(\".\"):]\n",
    "    extension2 = files2[0][files2[0].rfind(\".\"):]\n",
    "\n",
    "    files1_filtered = set()\n",
    "    files2_filtered = set()\n",
    "    \n",
    "    for f1 in files1:\n",
    "        files1_filtered.add(extract_fname(f1))\n",
    "    for f2 in files2:\n",
    "        files2_filtered.add(extract_fname(f2))\n",
    "    \n",
    "    complete_files = files1_filtered.intersection(files2_filtered)\n",
    "    missing_files = sorted(list(files1_filtered.union(files2_filtered) - complete_files))\n",
    "\n",
    "    # print Missing files\n",
    "    if print_missing:\n",
    "        for mf in missing_files:\n",
    "            if mf in files1_filtered:\n",
    "                print(\"WARNING: {} - {} companion missing\".format(mf, extension2))\n",
    "            if mf in files2_filtered:\n",
    "                print(\"WARNING: {} - {} companion missing\".format(mf, extension1))\n",
    "    return sorted(list(complete_files))\n",
    "\n",
    "DATA_PATH = \"./data/huawei/longrun/deterministic-15min/\"\n",
    "GROUND_TRUTH_PATH = \"./data/huawei/longrun/deterministic-15min/ground-truth/\"\n",
    "CHECKED_GT = \"./data/huawei/longrun/deterministic-15min/checked-gt/\"\n",
    "\n",
    "data_path_content = sorted(glob.glob(DATA_PATH + '*.csv', recursive=True))\n",
    "gt_path_content = sorted(glob.glob(GROUND_TRUTH_PATH + '*.log', recursive=True))\n",
    "checked_gt_path_content = sorted(glob.glob(CHECKED_GT + '*.log', recursive=True))\n",
    "\n",
    "\n",
    "# All data that can be used must have their .log companion (in ground-truth)\n",
    "ready_dataset = intersection_fname(data_path_content, gt_path_content)\n",
    "# All checkeds that can be used must have their .log companion (in ground-truth)\n",
    "checked_files = intersection_fname([f + \".log\" for f in ready_dataset], checked_gt_path_content, print_missing=False)\n",
    "\n",
    "# All data that can be used to evaluate the model\n",
    "path_files_data = [DATA_PATH + f + \".csv\" for f in ready_dataset]\n",
    "path_files_ground_truth = [GROUND_TRUTH_PATH + f + \".log\" for f in ready_dataset]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ground_truth\n",
    "#### Estimating delay between groundtruth and csv file (boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_longrun_log_file(longrunLogFile, all_action=None):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        longrunLogFile : File log name (including path)\n",
    "        all_action : actions used to train the model (needed to filter out actions not part of the training set)\n",
    "    \n",
    "    Return\n",
    "        [[time, action],] : filtered and clean version of the content of a logfile\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    with open(longrunLogFile, \"r\") as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',', skipinitialspace=True)\n",
    "        next(csv_reader)\n",
    "        for i, line in enumerate(csv_reader):\n",
    "            if all_action is None or line[1] in all_action:\n",
    "                out.append(line)\n",
    "    return out\n",
    "            \n",
    "def read_longrun_log_files(longrunLogFiles, all_action=None):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        longrunLogFiles : a list of files log names (including path)\n",
    "        all_action : actions used to train the model (needed to filter out actions not part of the training set)\n",
    "    \n",
    "    Return\n",
    "        dict[filename] = [[time, action],] : filtered and clean version of the content of multiple logfile\n",
    "    \"\"\"\n",
    "    out = dict()\n",
    "    for longrunLogFile in longrunLogFiles:\n",
    "        out[extract_fname(longrunLogFile)] = read_longrun_log_file(longrunLogFile, all_action)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_files_data_boundaries = [DATA_PATH + f + \".log\" for f in checked_files]\n",
    "path_files_ground_truth_boundaries = [GROUND_TRUTH_PATH + f + \".log\" for f in checked_files]\n",
    "path_files_checked_boundaries = [CHECKED_GT + f + \".log\" for f in checked_files]\n",
    "\n",
    "content_checked_boundaries = read_longrun_log_files(path_files_checked_boundaries, all_actions)\n",
    "content_ground_truth_boundaries = read_longrun_log_files(path_files_ground_truth_boundaries, all_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepency between automate and manually checked gournd-truth for action launch time differece:\n",
      "\n",
      "   mean_diff = 5.078723404255315\n",
      "   max_diff=16.5\n",
      "   min_diff=0.39999999999997726\n",
      "\n",
      " adapting correct new bound with lower = 0.39999999999997726, upper = 16.5\n"
     ]
    }
   ],
   "source": [
    "def record_diff_checked_gt(checkeds, gts, all_actions):\n",
    "    \"\"\"\n",
    "    Aggregate and filter the recordings timing difference between checked and ground-truth accross all files \n",
    "    \"\"\"\n",
    "    recordings = []\n",
    "    for checked, gt in zip(checkeds, gts):\n",
    "        action = gt[1]\n",
    "        if action is None:\n",
    "            print(\"ERROR: Parsing failure\")\n",
    "            break\n",
    "        if eval(checked[0]) is None or action not in all_actions:\n",
    "            continue\n",
    "\n",
    "        recordings.append(float(checked[0]) - float(gt[0]))  # add the difference between \n",
    "    return recordings\n",
    "\n",
    "\n",
    "recordings = []\n",
    "\n",
    "for capt in content_checked_boundaries:\n",
    "    checkeds = content_checked_boundaries[capt]\n",
    "    gts = content_ground_truth_boundaries[capt]\n",
    "    recordings += record_diff_checked_gt(checkeds, gts, all_actions)\n",
    "rec = np.array(recordings)\n",
    "\n",
    "print(\"Discrepency between automate and manually checked gournd-truth for action launch time differece:\\n\")\n",
    "print(\"   mean_diff = {}\\n   max_diff={}\\n   min_diff={}\\n\".format(np.mean(rec), np.max(rec), np.min(rec)))\n",
    "margin_timing_difference = 0\n",
    "upper = np.max(np.array(recordings)) + margin_timing_difference\n",
    "lower =  np.min(np.array(recordings)) - margin_timing_difference\n",
    "print(\" adapting correct new bound with lower = {}, upper = {}\".format(lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_bound_for_timing_in_action(content_ground_truth, lower, upper):\n",
    "    content_ground_truth_with_bound = dict()\n",
    "    for gt in content_ground_truth:\n",
    "        new_gt = []\n",
    "        for i, action in content_ground_truth[gt]:\n",
    "            lower_bound = float(i) + lower\n",
    "            upper_bound = float(i) + upper\n",
    "            new_gt.append((lower_bound, upper_bound, action))\n",
    "        content_ground_truth_with_bound[gt] = new_gt\n",
    "    return content_ground_truth_with_bound\n",
    "bounded_gt = make_bound_for_timing_in_action(content_ground_truth_boundaries, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_critical_point(time_serie):\n",
    "    # find Critcal points: where we have more than 2k data\n",
    "    ts = pd.Series(data = time_serie['ys'], index = pd.to_timedelta(time_serie[\"xs\"], 'sec'))\n",
    "\n",
    "    # filter out packets with no payload length and (or not) the ones that contains < 26 bits\n",
    "    ts = ts.map(abs)[ts != 0] #[ts > 26]\n",
    "\n",
    "    def time_delta_to_float(td):\n",
    "        if len(td) == 0:\n",
    "            return None\n",
    "        return float(str(td[0].seconds) +\".\" + str(td[0].microseconds))\n",
    "\n",
    "    # Compute the moving average of 30 seconds head in data PayloadLength\n",
    "\n",
    "    stw = ts[::-1].rolling(\"20s\").sum()[::-1]\n",
    "    stw = stw[stw > 200]  # filter out minimum 200B payload (banned app)\n",
    "\n",
    "\n",
    "    stw = stw.resample('5s').apply(lambda x: x.index) # 5 seconds jump\n",
    "    critical_points = stw.map(time_delta_to_float).dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_ground_truth = read_longrun_log_files(path_files_ground_truth, all_actions)\n",
    "bounded_gt = make_bound_for_timing_in_action(content_ground_truth, lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stw'></a>\n",
    "## Sliding Time Window\n",
    "[table of content](#tc)\n",
    "\n",
    "Adventage: does not need supervision for the data\n",
    "\n",
    "Idea to improve: Take the noApp noAcction > 200KB and train a model to predict noise\n",
    "\n",
    "Preprocessing: Remove\n",
    "for each 5\n",
    "\n",
    "\n",
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importation\n",
    "<a id='stw'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [],
   "source": [
    "# longrunCaptFile = \"./data/huawei/longrun/deterministic-15min/longrun_deterministic_20-04-03_02-42-49.csv\"\n",
    "# gt_f = \"./data/huawei/longrun/deterministic-15min/ground-truth/longrun_deterministic_20-04-03_02-42-49.log\"\n",
    "\n",
    "correct = False\n",
    "\n",
    "if not correct:\n",
    "\n",
    "    longrunCaptFile = \"./data/huawei/longrun/deterministic-15min/longrun_deterministic_20-04-03_02-59-25.csv\"\n",
    "    gt_f = \"./data/huawei/longrun/deterministic-15min/ground-truth/longrun_deterministic_20-04-03_02-59-25.log\"\n",
    "else:\n",
    "    longrunCaptFile = \"./data/huawei/longrun/deterministic-15min/longrun_deterministic_20-04-03_02-42-49.csv\"\n",
    "    gt_f = \"./data/huawei/longrun/deterministic-15min/ground-truth/longrun_deterministic_20-04-03_02-42-49.log\"\n",
    "\n",
    "\n",
    "\n",
    "gt = read_longrun_log_file(gt_f, all_actions)\n",
    "columns = extract_columns(longrunCaptFile)\n",
    "packets = read_file(longrunCaptFile, columns)\n",
    "packets = packet_store_cleanup(packets)\n",
    "time_serie = packets_to_timesize_tuples(packets)\n",
    "\n",
    "\n",
    "# find Critcal points: where we have more than 2k data\n",
    "ts = pd.Series(data = time_serie['ys'], index = pd.to_timedelta(time_serie[\"xs\"], 'sec'))\n",
    "\n",
    "# filter out packets with no payload length and (or not) the ones that contains < 26 bits\n",
    "ts = ts.map(abs)[ts != 0] #[ts > 26]\n",
    "\n",
    "\n",
    "def extract_indexes_in_groups(x):\n",
    "    return x.index.tolist()\n",
    "\n",
    "def time_delta_to_float(td):\n",
    "    if len(td) == 0:\n",
    "        return None\n",
    "    return float(str(td[0].seconds) +\".\" + str(td[0].microseconds))\n",
    "\n",
    "# Compute the moving average of 30 seconds head in data PayloadLength\n",
    "\n",
    "stw = ts[::-1].rolling(\"20s\").sum()[::-1]\n",
    "stw = stw[stw > 200]  # filter out minimum 200B payload (banned app)\n",
    "\n",
    "\n",
    "stw = stw.resample('5s').apply(extract_indexes_in_groups)  # 5 seconds jump\n",
    "\n",
    "\n",
    "critical_points = stw.map(time_delta_to_float).dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 22.714694,  59.465249,  62.720255,  67.715268,  72.965279,\n",
       "        80.465277,  83.104035,  87.96466 ,  97.714643, 108.214624,\n",
       "       122.464598, 142.715186, 149.464558, 153.964565, 157.717074,\n",
       "       163.714574, 167.768335, 174.214577, 177.917078, 184.71457 ,\n",
       "       188.464562, 195.964549, 204.964533, 213.964516, 224.464496,\n",
       "       229.715111, 232.974494, 239.464481, 243.214476, 249.215089,\n",
       "       306.214995, 307.902501, 330.964968, 333.34974 , 387.964867,\n",
       "       393.964247, 401.465484, 405.214226, 408.214845, 413.46422 ,\n",
       "       418.572346, 423.964223, 446.464179, 450.214797, 470.464133,\n",
       "       472.714765, 477.964128, 483.214118, 491.464726, 493.47231 ,\n",
       "       497.717244, 515.467228, 517.715985, 574.717125, 579.214001,\n",
       "       584.464618, 588.158379, 595.713989, 610.713958, 656.464493,\n",
       "       658.566999, 672.963849, 682.71383 , 687.963818, 709.7144  ,\n",
       "       713.463776, 740.464347, 743.715606, 762.214321, 765.21369 ,\n",
       "       778.713662, 789.21364 , 799.713618, 826.713566, 828.232948,\n",
       "       904.714052, 908.109686, 913.670324, 917.725959, 924.963457,\n",
       "       932.464069, 933.469695, 938.463443, 942.964071, 948.11582 ])"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "critical_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "longrunCaptFile = \"./data/huawei/longrun/longrun_deterministic_20-04-03_04-23-24.csv\"\n",
    "gt_f = \"./data/huawei/longrun/ground-truth/longrun_deterministic_20-04-03_04-23-24.log\"\n",
    "\n",
    "\n",
    "captures = dict()\n",
    "for longrunCaptFile in data_path_content:\n",
    "    \n",
    "    columns = extract_columns(longrunCaptFile)\n",
    "    packets = read_file(longrunCaptFile, columns)\n",
    "    packets = packet_store_cleanup(packets)\n",
    "    time_serie = packets_to_timesize_tuples(packets)\n",
    "    captures[extract_fname(longrunCaptFile)] = time_serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='implementation_stw'></a>\n",
    "## Implementation\n",
    "[Table of Content](#tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longrun_deterministic_20-04-03_02-42-49\n",
      "longrun_deterministic_20-04-03_02-59-25\n",
      "longrun_deterministic_20-04-03_03-16-03\n",
      "longrun_deterministic_20-04-03_03-32-47\n",
      "longrun_deterministic_20-04-03_03-49-15\n",
      "longrun_deterministic_20-04-03_04-06-24\n",
      "longrun_deterministic_20-04-03_04-23-24\n",
      "longrun_deterministic_20-04-03_04-39-20\n",
      "longrun_deterministic_20-04-03_04-55-47\n",
      "longrun_deterministic_20-04-03_05-12-52\n",
      "longrun_deterministic_20-04-03_05-29-28\n",
      "longrun_deterministic_20-04-03_05-46-07\n",
      "longrun_deterministic_20-04-03_06-03-24\n",
      "longrun_deterministic_20-04-03_06-20-26\n",
      "longrun_deterministic_20-04-03_06-37-03\n",
      "longrun_deterministic_20-04-03_06-53-52\n",
      "longrun_deterministic_20-04-03_07-10-45\n",
      "longrun_deterministic_20-04-03_07-27-29\n",
      "longrun_deterministic_20-04-03_07-44-02\n",
      "longrun_deterministic_20-04-03_08-00-50\n",
      "longrun_deterministic_20-04-03_10-59-20\n",
      "longrun_deterministic_20-04-03_11-16-04\n",
      "longrun_deterministic_20-04-03_11-33-07\n",
      "longrun_deterministic_20-04-03_11-49-30\n",
      "longrun_deterministic_20-04-03_12-06-04\n",
      "longrun_deterministic_20-04-03_12-23-06\n",
      "longrun_deterministic_20-04-03_12-39-43\n",
      "longrun_deterministic_20-04-03_12-55-52\n",
      "longrun_deterministic_20-04-03_13-12-43\n",
      "longrun_deterministic_20-04-03_13-29-48\n",
      "longrun_deterministic_20-04-03_15-51-29\n",
      "longrun_deterministic_20-04-03_16-08-53\n",
      "longrun_deterministic_20-04-03_16-25-52\n",
      "longrun_deterministic_20-04-03_16-41-59\n",
      "longrun_deterministic_20-04-03_16-59-16\n",
      "longrun_deterministic_20-04-03_17-15-57\n"
     ]
    }
   ],
   "source": [
    "predicted = dict()\n",
    "for capture in captures:\n",
    "    print(capture)\n",
    "    predicted[capture] = predict(captures[capture])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_critical_point(time_serie):\n",
    "    # find Critcal points: where we have more than 2k data\n",
    "    ts = pd.Series(data = time_serie['ys'], index = pd.to_timedelta(time_serie[\"xs\"], 'sec'))\n",
    "\n",
    "    # filter out packets with no payload length and (or not) the ones that contains < 26 bits\n",
    "    ts = ts.map(abs)[ts != 0] #[ts > 26]\n",
    "    \n",
    "    \n",
    "    def extract_indexes_in_groups(x):\n",
    "        return x.index.tolist()\n",
    "    \n",
    "    def time_delta_to_float(td):\n",
    "        if len(td) == 0:\n",
    "            return None\n",
    "        return float(str(td[0].seconds) +\".\" + str(td[0].microseconds))\n",
    "\n",
    "    # Compute the moving average of 30 seconds head in data PayloadLength\n",
    "\n",
    "    stw = ts[::-1].rolling(\"20s\").sum()[::-1]\n",
    "    stw = stw[stw > 200]  # filter out minimum 200B payload (banned app)\n",
    "\n",
    "\n",
    "    stw = stw.resample('5s').apply(extract_indexes_in_groups) # 5 seconds jump\n",
    "    \n",
    "    \n",
    "    critical_points = stw.map(time_delta_to_float).dropna().values\n",
    "    return critical_points\n",
    "\n",
    "\n",
    "\n",
    "def find_action_end(xs_capt, ys_capt, FILTER_LENGTH_LIMIT=46 ,INTER_TIMER_EVENT_CUTOFF=5):\n",
    "    \"\"\"\n",
    "    return the potential end of the action that begins at indicce j\n",
    "    xs_capt : time elements\n",
    "    ys_capt : length elements\n",
    "    FILTER_LENGTH_LIMIT : do not take length <= n\n",
    "    INTER_TIMER_EVENT_CUTOFF ; Do not take into accout \n",
    "    \n",
    "    return indices of the en\n",
    "    \"\"\"\n",
    "    xs_no_zeros = [x  for y, x in zip(ys_capt, xs_capt) if abs(y) > FILTER_LENGTH_LIMIT]\n",
    "    for i, x0 in enumerate(xs_no_zeros):\n",
    "        if i + 1 == len(xs_no_zeros):\n",
    "            return xs_capt[-1]  # reached the end\n",
    "        x1 = xs_no_zeros[i + 1]\n",
    "        inter_time = x1-x0\n",
    "        if inter_time > INTER_TIMER_EVENT_CUTOFF:\n",
    "            return x0\n",
    "        \n",
    "def find_x_indices(xs_capt, j, xs_end):\n",
    "    for i, x in enumerate(xs_capt[j:]):\n",
    "        if xs_end <= x:\n",
    "            return i + j\n",
    "\n",
    "\n",
    "\n",
    "def predict(time_serie):\n",
    "    critical_points = find_critical_point(time_serie)\n",
    "\n",
    "\n",
    "    predicted = []  # tuple list of \n",
    "    critical_points_i = 0\n",
    "    xs_end = -1\n",
    "    xs_capt = time_serie[\"xs\"]\n",
    "    ys_capt = time_serie[\"ys\"]\n",
    "\n",
    "\n",
    "\n",
    "    for i, _ in enumerate(xs_capt):\n",
    "\n",
    "\n",
    "        current_xs = xs_capt[i]\n",
    "        critical_point = critical_points[critical_points_i]\n",
    "        if current_xs > critical_point and current_xs > xs_end:\n",
    "\n",
    "            j = i-1   # take previous one since we are one step further\n",
    "\n",
    "            xs_start = xs_capt[i]\n",
    "            xs_end = find_action_end(xs_capt[i:], ys_capt[i:])\n",
    "            end_indice = find_x_indices(xs_capt, j, xs_end)\n",
    "            xy = dict()\n",
    "            xy[\"xs\"] = xs_capt[j:end_indice+1]\n",
    "            xy[\"ys\"] = ys_capt[j:end_indice+1]\n",
    "            features_dict = extract_features(xy)\n",
    "            features = list(features_dict.values())\n",
    "            y = clf.predict(np.array(features).reshape(1,-1))\n",
    "            predicted.append((xs_start, xs_end, y[0]))\n",
    "\n",
    "            while critical_points[critical_points_i] < xs_end:\n",
    "                critical_points_i +=1\n",
    "                if critical_points_i == len(critical_points):\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if critical_points_i == len(critical_points) or xs_end == xs_capt[-1]:\n",
    "            break\n",
    "    return predicted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(42.611644875, 56.7222565, 'Outlook_open'),\n",
       " (58.536010375, 65.8197485, 'Translate_open'),\n",
       " (67.709129375, 144.62143025, 'SalatTime_open'),\n",
       " (148.3614295, 167.175752, 'Citymapper_open'),\n",
       " (167.857003375, 179.1219935, 'Telegram_force-stop'),\n",
       " (182.86074325, 251.90429075, 'SalatTime_open'),\n",
       " (252.856170125, 258.806162875, 'Shazam_open'),\n",
       " (296.111065625, 310.3641705, 'WashPost_force-stop'),\n",
       " (312.611674, 347.16036525, 'Meduza_open'),\n",
       " (349.116618875, 357.247222875, 'Spotify_force-stop'),\n",
       " (358.25909875, 417.887052875, 'FoursquareCityGuide_force-stop'),\n",
       " (429.611402375, 437.706411875, 'FoursquareCityGuide_food'),\n",
       " (437.70953825, 444.61452975, 'WashPost_force-stop'),\n",
       " (448.360778625, 450.82452425, 'FoursquareCityGuide_force-stop'),\n",
       " (452.850151125, 510.0643555, 'MapMyRun_open'),\n",
       " (515.109974125, 528.648683875, 'Citymapper_open'),\n",
       " (533.109933125, 547.36364225, 'Spotify_force-stop'),\n",
       " (548.4686445, 590.194188125, 'FoursquareCityGuide_open'),\n",
       " (593.109813375, 610.28479375, 'FoursquareCityGuide_food'),\n",
       " (612.612296125, 618.6179075, 'Spotify_force-stop'),\n",
       " (624.61040225, 624.8966535, 'Endomondo_browseMap'),\n",
       " (627.6129045, 683.159634125, 'Lifesum_open'),\n",
       " (707.11082625, 773.89944625, 'PlayStore_open'),\n",
       " (781.3600625, 795.97752775, 'Weather_open'),\n",
       " (797.96878225, 880.361794125, 'Meduza_open'),\n",
       " (882.6117985, 951.16600275, 'Weather_open'),\n",
       " (953.12350725, 980.859701125, 'KeepNotes_open')]"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(captures[\"longrun_deterministic_20-04-03_11-16-04\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(a, b):\n",
    "    return not (b[0] > a[1] or a[0] > b[1])\n",
    "\n",
    "def overlap_length(a,b):\n",
    "    if not overlaps(a, b):\n",
    "        return 0\n",
    "    return  min(a[1], b[1]) - max(a[0], b[0])\n",
    "\n",
    "def compute_eval_metric_v1(prediciton, ground_truth, print_details=True):\n",
    "    \"\"\"\n",
    "    calculate accuarcy, precision and recall \n",
    "    Args:\n",
    "        prediction : [(start, stop, action),] list of predicition with time boundaries\n",
    "        ground_truth : [(start, stop, action),] list of ground_turh associated with the prediction\n",
    "        \n",
    "    Return (tp, fp, fn) True Positive, False Positive and False Negative\n",
    "    \"\"\"\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    i_pred, i_gt = 0, 0\n",
    "    correct_pred, wrong_pred, missed_pred = [], [], []\n",
    "    last_run = False\n",
    "\n",
    "    while True:\n",
    "        # Make sure indices are not overflowing\n",
    "        i_pred_m = min(i_pred, len(prediciton) - 1)\n",
    "        i_gt_m = min(i_gt, len(ground_truth) - 1)\n",
    "        \n",
    "        start_pred, stop_pred = prediciton[i_pred_m][0], prediciton[i_pred_m][1]\n",
    "        action_pred = prediciton[i_pred_m][2]\n",
    "\n",
    "        start_gt, stop_gt = ground_truth[i_gt_m][0], ground_truth[i_gt_m][1]\n",
    "        action_gt = ground_truth[i_gt_m][2]\n",
    "        \n",
    "        if print_details:\n",
    "            print(\"\\nChecking : \\npred: \", action_pred, \"\\n gt : \", action_gt)\n",
    "\n",
    "        if overlaps((start_pred, stop_pred), (start_gt, stop_gt)) and action_gt == action_pred:\n",
    "            i_pred += 1\n",
    "            i_gt += 1\n",
    "            tp += 1\n",
    "            correct_pred.append(action_gt)\n",
    "            if print_details:\n",
    "                print(action_gt + \" correct (tp + 1 = \", tp,\")\")\n",
    "\n",
    "        \n",
    "        elif stop_pred > stop_gt and i_gt != len(ground_truth):\n",
    "            i_gt += 1\n",
    "            fn += 1\n",
    "            missed_pred.append(action_gt)\n",
    "            if print_details:\n",
    "                print(action_gt, \" missed prediction (fn + 1= \", fn,\")\")\n",
    "            \n",
    "        elif stop_gt > stop_pred and i_pred != len(prediciton):\n",
    "            i_pred += 1\n",
    "            fp += 1\n",
    "            wrong_pred.append(action_pred)\n",
    "            if print_details:\n",
    "                print(action_pred + \" wrong prediction (fp + 1= \", fp, \")\")\n",
    "        else:\n",
    "            print(\"HELP\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        if i_pred >= len(prediciton) - 1 and i_gt >= len(ground_truth) -1:\n",
    "            break\n",
    "        \n",
    "    print(i_pred, i_gt)\n",
    "\n",
    "\n",
    "    return correct_pred, wrong_pred, missed_pred\n",
    "\n",
    "\n",
    "def compute_eval_metric_v2(prediciton, ground_truth, print_details=True):\n",
    "    \"\"\"\n",
    "    calculate accuarcy, precision and recall \n",
    "    Args:\n",
    "        prediction : [(start, stop, action),] list of predicition with time boundaries\n",
    "        ground_truth : [(start, stop, action),] list of ground_turh associated with the prediction\n",
    "        \n",
    "    Return (tp, fp, fn) True Positive, False Positive and False Negative\n",
    "    \"\"\"\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    i_pred, i_gt = 0, 0\n",
    "    correct_pred, wrong_pred, missed_gt, correct_gt = [], [], [], []\n",
    "    last_run = False\n",
    "    \n",
    "    \n",
    "    def add_wrong_pred(pred, fp):\n",
    "        fp += 1\n",
    "        wrong_pred.append(pred)\n",
    "        if print_details:\n",
    "            print(pred[2] + \" wrong prediction (fp + 1= \", fp, \")\")\n",
    "        return fp\n",
    "            \n",
    "    def add_missed_gt(gt, fn):\n",
    "        fn += 1\n",
    "        missed_gt.append(gt)\n",
    "        if print_details:\n",
    "            print(gt[2], \" missed prediction (fn + 1= \", fn,\")\")\n",
    "        return fn\n",
    "            \n",
    "    def add_correct_pred(pred, tp):\n",
    "        tp += 1\n",
    "        correct_pred.append(pred)\n",
    "        if print_details:\n",
    "            print(pred[2] + \" correct pref (tp + 1 = \", tp,\")\")\n",
    "        return tp\n",
    "    \n",
    "    def add_correct_gt(gt):\n",
    "        correct_gt.append(gt)\n",
    "        if print_details:\n",
    "            print(gt[2], \" correct gt\")\n",
    "        return fn\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    matched_pred = []\n",
    "    for gt in ground_truth:\n",
    "        start_gt, stop_gt, action_gt = gt\n",
    "        \n",
    "        match = []\n",
    "        for pred in prediciton:\n",
    "            start_pred, stop_pred, action_pred = pred\n",
    "            \n",
    "                \n",
    "            # we found a match\n",
    "            if overlaps((start_pred, stop_pred), (start_gt, stop_gt)) and action_gt == action_pred:\n",
    "                match.append((pred, overlap_length((start_pred, stop_pred), (start_gt, stop_gt))))\n",
    "        \n",
    "        if len(match) == 0:\n",
    "            fn = add_missed_gt(gt, fn)\n",
    "            continue\n",
    "        \n",
    "        best_matchs = sorted(match,key=lambda item:-item[1])[0]\n",
    "        for bm in best_matchs:\n",
    "            if not bm in correct_pred:\n",
    "                tp = add_correct_pred(bm, tp)\n",
    "                break\n",
    "        \n",
    "    # compute wrong pred:\n",
    "    for pred in prediciton:        \n",
    "        if pred not in correct_pred:\n",
    "            fp = add_wrong_pred(pred, fp)\n",
    "\n",
    "    return correct_pred, wrong_pred, missed_gt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Telegram_open correct pref (tp + 1 =  1 )\n",
      "Telegram_force-stop  missed prediction (fn + 1=  1 )\n",
      "FitWorkout_open  missed prediction (fn + 1=  2 )\n",
      "SalatTime_open correct pref (tp + 1 =  2 )\n",
      "MapMyRun_open correct pref (tp + 1 =  3 )\n",
      "SalatTime_open correct pref (tp + 1 =  4 )\n",
      "Shazam_open correct pref (tp + 1 =  5 )\n",
      "Outlook_open correct pref (tp + 1 =  6 )\n",
      "Translate_open correct pref (tp + 1 =  7 )\n",
      "Translate_force-stop  missed prediction (fn + 1=  3 )\n",
      "MapMyRun_open correct pref (tp + 1 =  8 )\n",
      "Running_open correct pref (tp + 1 =  9 )\n",
      "Running_force-stop  missed prediction (fn + 1=  4 )\n",
      "Lifesum_open correct pref (tp + 1 =  10 )\n",
      "Lifesum_addWater  missed prediction (fn + 1=  5 )\n",
      "Lifesum_force-stop  missed prediction (fn + 1=  6 )\n",
      "Weather_open wrong prediction (fp + 1=  1 )\n",
      "FindMyPhone_force-stop wrong prediction (fp + 1=  2 )\n",
      "SalatTime_open wrong prediction (fp + 1=  3 )\n",
      "Maps_force-stop wrong prediction (fp + 1=  4 )\n",
      "precision = 0.7142857142857143, recall = 0.625\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "(correct_pred, wrong_pred, missed_gt) = compute_eval_metric_v2(predicted , bounded_gt['longrun_deterministic_20-04-03_02-42-49'], print_details=True)\n",
    "\n",
    "tp, fp, fn = len(correct_pred), len(wrong_pred), len(missed_pred)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"precision = {}, recall = {}\".format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "longrun_deterministic_20-04-03_02-42-49\n",
      "precision = 0.7142857142857143, recall = 0.625\n",
      "\n",
      "longrun_deterministic_20-04-03_02-59-25\n",
      "precision = 0.42105263157894735, recall = 0.47058823529411764\n",
      "\n",
      "longrun_deterministic_20-04-03_03-16-03\n",
      "precision = 0.6111111111111112, recall = 0.4583333333333333\n",
      "\n",
      "longrun_deterministic_20-04-03_03-32-47\n",
      "precision = 0.47619047619047616, recall = 0.5882352941176471\n",
      "\n",
      "longrun_deterministic_20-04-03_03-49-15\n",
      "precision = 0.4782608695652174, recall = 0.4782608695652174\n",
      "\n",
      "longrun_deterministic_20-04-03_04-06-24\n",
      "precision = 0.4090909090909091, recall = 0.4090909090909091\n",
      "\n",
      "longrun_deterministic_20-04-03_04-23-24\n",
      "precision = 0.030303030303030304, recall = 0.125\n",
      "\n",
      "longrun_deterministic_20-04-03_04-39-20\n",
      "precision = 0.35, recall = 0.3888888888888889\n",
      "\n",
      "longrun_deterministic_20-04-03_04-55-47\n",
      "precision = 0.43478260869565216, recall = 0.5\n",
      "\n",
      "longrun_deterministic_20-04-03_05-12-52\n",
      "precision = 0.5263157894736842, recall = 0.45454545454545453\n",
      "\n",
      "longrun_deterministic_20-04-03_05-29-28\n",
      "precision = 0.3684210526315789, recall = 0.4117647058823529\n",
      "\n",
      "longrun_deterministic_20-04-03_05-46-07\n",
      "precision = 0.48, recall = 0.46153846153846156\n",
      "\n",
      "longrun_deterministic_20-04-03_06-03-24\n",
      "precision = 0.3448275862068966, recall = 0.5263157894736842\n",
      "\n",
      "longrun_deterministic_20-04-03_06-20-26\n",
      "precision = 0.8571428571428571, recall = 0.7058823529411765\n",
      "\n",
      "longrun_deterministic_20-04-03_06-37-03\n",
      "precision = 0.5263157894736842, recall = 0.625\n",
      "\n",
      "longrun_deterministic_20-04-03_06-53-52\n",
      "precision = 0.3333333333333333, recall = 0.3333333333333333\n",
      "\n",
      "longrun_deterministic_20-04-03_07-10-45\n",
      "precision = 0.391304347826087, recall = 0.42857142857142855\n",
      "\n",
      "longrun_deterministic_20-04-03_07-27-29\n",
      "precision = 0.5294117647058824, recall = 0.5294117647058824\n",
      "\n",
      "longrun_deterministic_20-04-03_07-44-02\n",
      "precision = 0.3333333333333333, recall = 0.3157894736842105\n",
      "\n",
      "longrun_deterministic_20-04-03_08-00-50\n",
      "precision = 0.5714285714285714, recall = 0.631578947368421\n",
      "\n",
      "longrun_deterministic_20-04-03_10-59-20\n",
      "precision = 0.45, recall = 0.5294117647058824\n",
      "\n",
      "longrun_deterministic_20-04-03_11-16-04\n",
      "precision = 0.25925925925925924, recall = 0.3684210526315789\n",
      "\n",
      "longrun_deterministic_20-04-03_11-33-07\n",
      "precision = 0.42857142857142855, recall = 0.5\n",
      "\n",
      "longrun_deterministic_20-04-03_11-49-30\n",
      "precision = 0.5555555555555556, recall = 0.5\n",
      "\n",
      "longrun_deterministic_20-04-03_12-06-04\n",
      "precision = 0.6, recall = 0.46153846153846156\n",
      "\n",
      "longrun_deterministic_20-04-03_12-23-06\n",
      "precision = 0.2857142857142857, recall = 0.47058823529411764\n",
      "\n",
      "longrun_deterministic_20-04-03_12-39-43\n",
      "precision = 0.32142857142857145, recall = 0.5294117647058824\n",
      "\n",
      "longrun_deterministic_20-04-03_12-55-52\n",
      "precision = 0.3684210526315789, recall = 0.3684210526315789\n",
      "\n",
      "longrun_deterministic_20-04-03_13-12-43\n",
      "precision = 0.25925925925925924, recall = 0.35\n",
      "\n",
      "longrun_deterministic_20-04-03_13-29-48\n",
      "precision = 0.48, recall = 0.48\n",
      "\n",
      "longrun_deterministic_20-04-03_15-51-29\n",
      "precision = 0.36, recall = 0.5294117647058824\n",
      "\n",
      "longrun_deterministic_20-04-03_16-08-53\n",
      "precision = 0.5, recall = 0.5714285714285714\n",
      "\n",
      "longrun_deterministic_20-04-03_16-25-52\n",
      "precision = 0.3103448275862069, recall = 0.47368421052631576\n",
      "\n",
      "longrun_deterministic_20-04-03_16-41-59\n",
      "precision = 0.56, recall = 0.5833333333333334\n",
      "\n",
      "longrun_deterministic_20-04-03_16-59-16\n",
      "precision = 0.47619047619047616, recall = 0.5555555555555556\n",
      "\n",
      "longrun_deterministic_20-04-03_17-15-57\n",
      "precision = 0.55, recall = 0.55\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/ipykernel_launcher.py:136: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "/usr/local/Cellar/jupyterlab/1.2.6/libexec/lib/python3.7/site-packages/ipykernel_launcher.py:142: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n"
     ]
    }
   ],
   "source": [
    "from time import sleep\n",
    "all_wrong_pred = []\n",
    "all_correct_pred = []\n",
    "all_missed_gt = []\n",
    "for capture in captures:\n",
    "    print(capture)\n",
    "    (correct_pred, wrong_pred, missed_gt) = compute_eval_metric_v2(predicted[capture] , bounded_gt[capture], print_details=False)\n",
    "    all_wrong_pred += wrong_pred\n",
    "    all_correct_pred += correct_pred\n",
    "    all_missed_gt += missed_gt\n",
    "    \n",
    "    tp, fp, fn = len(correct_pred), len(wrong_pred), len(missed_gt)\n",
    "\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    print(\"precision = {}, recall = {}\".format(precision, recall))\n",
    "    print()\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.4223057644110276, recall = 0.4821173104434907\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tp, fp, fn = len(all_correct_pred), len(all_wrong_pred), len(all_missed_gt)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"precision = {}, recall = {}\".format(precision, recall))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(58.9801365, 61.483892875, 'Krone_open'),\n",
       " (64.2288965, 84.88763575, 'Mobilis_open'),\n",
       " (92.72887925, 144.35251175, 'Krone_open'),\n",
       " (150.47875825, 228.634216375, 'Outlook_open'),\n",
       " (230.641095, 312.2802905, 'DiabetesM_open'),\n",
       " (313.980918, 398.90512225, 'FitBreathe_open'),\n",
       " (400.26387575, 486.676846625, 'PlayStore_open'),\n",
       " (490.228723375, 519.59054425, 'PlayStore_deterministicBrowse'),\n",
       " (540.478639, 589.251690875, 'Spotify_open'),\n",
       " (598.977931125, 626.732250875, 'Spotify_force-stop'),\n",
       " (628.9803805, 669.962190875, 'PlayStore_open'),\n",
       " (687.479033125, 745.414532625, 'Outlook_open'),\n",
       " (829.2287225, 865.433154, 'Endomondo_open'),\n",
       " (874.2281455, 953.72797525, 'Fit_open')]"
      ]
     },
     "execution_count": 562,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted[\"longrun_deterministic_20-04-03_06-20-26\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(54.199999999999974, 70.3, 'Krone_open'),\n",
       " (82.79999999999998, 98.9, 'Krone_force-stop'),\n",
       " (139.29999999999998, 155.4, 'Krone_open'),\n",
       " (167.99999999999997, 184.1, 'Krone_force-stop'),\n",
       " (223.29999999999998, 239.4, 'Outlook_open'),\n",
       " (307.09999999999997, 323.2, 'DiabetesM_open'),\n",
       " (390.59999999999997, 406.7, 'FitWorkout_open'),\n",
       " (473.7, 489.8, 'PlayStore_open'),\n",
       " (480.2, 496.3, 'PlayStore_deterministicBrowse'),\n",
       " (574.5, 590.6, 'Spotify_open'),\n",
       " (603.6, 619.7, 'Spotify_force-stop'),\n",
       " (657.9, 674.0, 'PlayStore_open'),\n",
       " (740.1, 756.2, 'Outlook_open'),\n",
       " (822.5, 838.6, 'Endomondo_open'),\n",
       " (829.0, 845.1, 'Endomondo_browseMap'),\n",
       " (863.1, 879.2, 'Endomondo_force-stop'),\n",
       " (918.9, 935.0, 'Fit_open')]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounded_gt[\"longrun_deterministic_20-04-03_06-20-26\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics: \n",
    "\n",
    "To evaluate the system, we first defined the following quantity:\n",
    "\n",
    "- TP: stands for True Positive. In our case, TP is defined as The number of correct prediction. The match\n",
    "- FP: stands for False Positive. The number of wrong prediction (either because of the timing or because of the label)\n",
    "- FN: stands for False Negative. The number of labels that was missed \n",
    "\n",
    "***Precision*** :\n",
    "   The Precision can be computed by the following formula:\n",
    "   $$\\frac{TP}{TP + FP}$$\n",
    "   \n",
    "   This quantity represents the fraction of time a prediction is correct regardless of rather there is no associated action at that time or the action is not the one predicted.\n",
    "\n",
    "\n",
    " \n",
    "***Recall***:\n",
    "    The recall can be computed by the following formula:\n",
    "    $$\\frac{TP}{TP + FN}$$\n",
    "    \n",
    "   This quantity represents the fraction of time actions performed on the smartwatch are corrected classified. (fraction of time we have a correct match in time and in label)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp + fp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp + fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
