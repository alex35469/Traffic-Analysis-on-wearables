{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long-run identificaiton\n",
    "\n",
    "<a id='tc'></a>\n",
    "## Table of content\n",
    "\n",
    "**PART I** - [Setup](#setup)\n",
    "1. [imports](#imports)\n",
    "2. [helpers](#helpers)\n",
    "3. [evaluate function](#evaluate)\n",
    "4. [build per action capture model](#build-per-action-capture-model)\n",
    "\n",
    "2. [sliding time window](#stw)\n",
    "    1. [implementation](#implementation_stw)\n",
    "    2. [Training](#evaluation_stw)\n",
    "        - No training, output simply majority voting\n",
    "        - Train on per-action capture: perform data augmentation (cut corp the data) labeled as 1. etc...and use NoApp NoAction labeled as 0 (maybe use same model as )\n",
    "        - Train on longrun capture with probabilities output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## PART I - Setup\n",
    "[table of content](#tc)\n",
    "<a id='imports'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import random\n",
    "from build_datasets import *\n",
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import kurtosis\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit, cross_val_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='helpers'></a>\n",
    "## Helpers\n",
    "[Table of Content](#tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Capture time serie\n",
    "\n",
    "all_columns = set()\n",
    "def extract_columns(dataset_file):\n",
    "    all_columns = set()\n",
    "\n",
    "    with open(dataset_file, \"r\") as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "        for i, line in enumerate(csv_reader):\n",
    "            all_columns.update(line)\n",
    "            return all_columns\n",
    "\n",
    "\n",
    "def new_packet(columns):\n",
    "    packet = dict()\n",
    "    for column in columns:\n",
    "        packet[column] = \"\"\n",
    "\n",
    "    return packet\n",
    "\n",
    "\n",
    "def read_file(dataset_file, columns):\n",
    "    \"\"\"\n",
    "    Reads a .csv file and puts its raw contents in packet_store[dataset_file]\n",
    "    \"\"\"\n",
    "    ID_COLUMN = \"Packet #\"\n",
    "    dataset_packet_store = dict() # packetID => packets\n",
    "    headers = []\n",
    "    with open(dataset_file, \"r\") as file:\n",
    "        reader = csv.reader(file, delimiter=',', quotechar='\"')\n",
    "\n",
    "        for i, line in enumerate(reader):\n",
    "            if i == 0:\n",
    "                headers = line\n",
    "                continue\n",
    "\n",
    "            packet = new_packet(columns)\n",
    "\n",
    "            for j, item in enumerate(line):\n",
    "                key = headers[j]\n",
    "                val = item\n",
    "\n",
    "                if key not in packet:\n",
    "                    print(packet)\n",
    "                    print(\"Fatal: column '{}' not found in packet; all_columns is {}\".format(key, columns))\n",
    "                    sys.exit(1)\n",
    "                packet[key] = val\n",
    "\n",
    "            packet_id = toInt(packet[ID_COLUMN].replace('\\'', ''))\n",
    "            if packet_id not in dataset_packet_store:\n",
    "                dataset_packet_store[packet_id] = []\n",
    "\n",
    "            dataset_packet_store[packet_id].append(packet)\n",
    "\n",
    "    return dataset_packet_store\n",
    "\n",
    "def extract_payload_length(payload_string, default=0):\n",
    "    payload_string = payload_string.strip()\n",
    "    if payload_string == \"\" or \"No data\" in payload_string:\n",
    "        return default\n",
    "    parts = payload_string.split(' ')\n",
    "    return toInt(parts[0])\n",
    "\n",
    "def packet_store_cleanup(packets): #dataset_packet_store is packetID => packets\n",
    "    for packet_id in packets:\n",
    "        layers = packets[packet_id]\n",
    "        for layer in layers:\n",
    "            layer[ID_COLUMN] = toInt(layer[ID_COLUMN])\n",
    "            layer[\"Time\"] = toFloat(layer[\"Time\"], default=-1)\n",
    "            layer[\"Time delta\"] = toFloat(layer[\"Time delta\"], default=-1)\n",
    "            layer[\"PayloadLength\"] = extract_payload_length(layer[\"Payload\"], default=0)\n",
    "            layer[\"PayloadRaw\"] = extract_payload_bytes(layer[\"Payload\"])\n",
    "    return packets\n",
    "\n",
    "\n",
    "def packets_to_timesize_tuples(packets):\n",
    "    global master\n",
    "    xy = dict(xs=[], ys=[])\n",
    "    packets_ids = list(packets.keys())\n",
    "    packets_ids.sort(reverse=False)\n",
    "\n",
    "    # Ensure that the direction stays the same even if HUAWEI Watch becomes master\n",
    "\n",
    "\n",
    "    for packet_id in packets_ids:\n",
    "        for layer in packets[packet_id]:\n",
    "            master = extract_master(layer[\"Communication\"])\n",
    "            if master in POSSIBLE_MASTERS:\n",
    "                direction = 1\n",
    "            else:\n",
    "                print(\"WARNING master not in Possible masters: '\" + master + \"'\")\n",
    "                print(layer[\"Communication\"])\n",
    "                direction = -1\n",
    "\n",
    "            if not \"master\" in layer['Transmitter'].lower():\n",
    "                direction *= -1\n",
    "            xy['xs'].append(float(layer['Time']))\n",
    "            xy['ys'].append(direction * int(layer['PayloadLength']))\n",
    "    return xy\n",
    "\n",
    "\n",
    "\n",
    "def merge_actions_in_app(events, to_merge):\n",
    "    for actions in to_merge:\n",
    "        events = merge_action_in_app(events, actions)\n",
    "    return events\n",
    "\n",
    "\n",
    "def merge_action_in_app(events, to_merge, separate_watch=True, maximum_level=None): # TODO separate watch\n",
    "    \"\"\"to_merge is of the form [app_feature_x1, app_feature_x2...]\n",
    "    Cannot merge across apps\n",
    "    \"\"\"\n",
    "    ## TODO: Make sure merge and \n",
    "    app = to_merge[0].split(\"_\")[0]\n",
    "    events_out = copy.deepcopy(events)\n",
    "    to_merge_action_set = set([f.split(\"_\")[1] for f in to_merge])\n",
    "    print(\"to_merge_action_set = \", to_merge_action_set)\n",
    "    for w in events:\n",
    "        for appli in events[w]:\n",
    "            if appli != app:\n",
    "                continue\n",
    "            merged_actions = []\n",
    "            labeled_actions = \"\"\n",
    "            for action in events[w][app]:\n",
    "                if action in to_merge_action_set:\n",
    "                    labeled_actions += action\n",
    "                    merged_actions += events[w][app][action]\n",
    "                    del events_out[w][app][action]\n",
    "            events_out[w][app][labeled_actions] = merged_actions\n",
    "    return events_out\n",
    "\n",
    "\n",
    "def discard_actions(source_files, to_discard):\n",
    "    sf_new = []\n",
    "    for f in source_files:\n",
    "        _in = False\n",
    "        for df in to_discard:\n",
    "            if df in f:\n",
    "                _in = True\n",
    "        if not _in:\n",
    "            sf_new.append(f)\n",
    "    return sf_new\n",
    "\n",
    "\n",
    "def build_features_labels_dataset(events, adversary_capture_duration=-1, unique_from=46, unique_to=1006):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for device in events:\n",
    "        for app in events[device]:\n",
    "            for action in events[device][app]:\n",
    "                label = app + \"_\" + action\n",
    "                for event in events[device][app][action]:\n",
    "                    features_dict = extract_features(event, adversary_capture_duration, unique_from, unique_to)\n",
    "                    features = list(features_dict.values())\n",
    "                    data.append(features)\n",
    "                    labels.append(label)\n",
    "\n",
    "    return data, labels\n",
    "\n",
    "\n",
    "\n",
    "def delete_different_action_across_watch(events):\n",
    "        # Create common action set if multiple watches\n",
    "    intersection_set = set()\n",
    "    for i, w in enumerate(events):\n",
    "        all_action = []\n",
    "        for app in events[w]:\n",
    "            actions = set(events[w][app].keys())\n",
    "            all_action += [app + \"_\" + act for act in actions]\n",
    "        if i == 0:\n",
    "            intersection_set = set(all_action)\n",
    "        else:\n",
    "            intersection_set = intersection_set.intersection(set(all_action))\n",
    "    \n",
    "    events_copy = copy.deepcopy(events)\n",
    "    # Delete not common action from dictionnary\n",
    "    for device in events_copy:\n",
    "        for app in events_copy[device]:\n",
    "            for action in events_copy[device][app]:\n",
    "                if app + \"_\" + action not in intersection_set:\n",
    "                    del events[device][app][action]\n",
    "    return events\n",
    "\n",
    "\n",
    "def equilibrate_events_across_apps_and_watch(events):\n",
    "    \"\"\"\n",
    "    Equilibrate the events by identifing the minimum number of samples per class\n",
    "    and discarding Randomly the extra samples present in the oder classes. \n",
    "    If there are multiple watchs, only the common application are kept\n",
    "\n",
    "    Parameters: \n",
    "        events (dict[watch][app][action] -> event): dataset \n",
    "\n",
    "    Returns: \n",
    "        events (dict[watch][app][action] -> event): equilibrate dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    events = delete_different_action_across_watch(events)\n",
    "    \n",
    "    # Find minimum samples \n",
    "    counts = dict()\n",
    "    for device in events:\n",
    "        for app in events[device]:\n",
    "            for action in events[device][app]:\n",
    "                counts[device + \"_\" + app +\"_\" + action] = 0\n",
    "            for action in events[device][app]:\n",
    "                counts[device + \"_\" + app + \"_\" + action] += len(events[device][app][action])\n",
    "\n",
    "    if len(counts.values())== 0:\n",
    "        return events\n",
    "\n",
    "\n",
    "    nb_samples_per_cat = min(counts.values())\n",
    "\n",
    "    events_out = dict()\n",
    "\n",
    "    # remove everything above the min across devices\n",
    "    for device in events:\n",
    "        for app in events[device]:\n",
    "\n",
    "            for action in events[device][app]:\n",
    "\n",
    "                if not device in events_out:\n",
    "                    events_out[device] = dict()\n",
    "                if not app in events_out[device]:\n",
    "                    events_out[device][app] = dict()\n",
    "                if not action in events_out[device][app]:\n",
    "                    events_out[device][app][action] = random.sample(events[device][app][action], k=nb_samples_per_cat)\n",
    "\n",
    "    counts = dict()\n",
    "    for device in events_out:\n",
    "        for app in events_out[device]:\n",
    "            if not app in counts:\n",
    "                counts[app] = 0\n",
    "            for action in events_out[device][app]:\n",
    "                counts[app] += len(events_out[device][app][action])\n",
    "\n",
    "    return events_out, nb_samples_per_cat\n",
    "\n",
    "\n",
    "\n",
    "def extract_features(xy, capture_duration_does_nothing=0, unique_from=46, unique_to=1006): # dataset is {'xs': [packet1, packet2,...], 'ys': [packet1, packet2,...]} where x is time and y is size\n",
    "    xs = xy['xs']\n",
    "    ys = xy['ys']\n",
    "    f = dict()\n",
    "\n",
    "    def take(arr, n=30):\n",
    "        if len(arr) > n:\n",
    "            return arr[:30]\n",
    "        return arr\n",
    "\n",
    "    def stats(key, data):\n",
    "        if len(data) == 0:\n",
    "            data=[-1]\n",
    "        f['min_'+key] = np.min(data)\n",
    "        f['mean_'+key] = np.mean(data)\n",
    "        f['max_'+key] = np.max(data)\n",
    "        f['count_'+key] = len(data)\n",
    "        f['std_'+key] = np.std(data)\n",
    "        f['kurtosis_'+key] = kurtosis(data)\n",
    "\n",
    "\n",
    "\n",
    "    # general statistics\n",
    "    stats(\"non_null\", [abs(y) for y in ys if y != 0])\n",
    "    stats(\"outgoing\", [abs(y) for y in ys if y > 0])\n",
    "    stats(\"incoming\", [abs(y) for y in ys if y < 0])\n",
    "    stats(\"outgoing_30\", [abs(y) for y in take(ys) if y > 0])\n",
    "    stats(\"incoming_30\", [abs(y) for y in take(ys) if y < 0])\n",
    "\n",
    "    # f[\"total_payload\"] = sum([abs(y) for y in ys])\n",
    "\n",
    "    # statistics about timings\n",
    "    x_deltas = []\n",
    "    i = 1\n",
    "    while i<len(xs):\n",
    "        x_deltas.append(xs[i]-xs[i-1])\n",
    "        i += 1\n",
    "\n",
    "    stats(\"x_deltas\", x_deltas)\n",
    "    stats(\"x_deltas_30\", take(x_deltas))\n",
    "\n",
    "    # bursts\n",
    "\n",
    "    # unique packet lengths [Liberatore and Levine; Herrmann et al.]\n",
    "    lengths = dict()\n",
    "    for i in range(unique_from, unique_to):\n",
    "        lengths[str(i)] = 0\n",
    "    for y in ys:\n",
    "        if str(abs(y)) in lengths:\n",
    "            lengths[str(abs(y))] += 1\n",
    "\n",
    "    lengths_array = list(lengths.values())\n",
    "    stats(\"unique_lengths\", lengths_array)\n",
    "    for l in lengths:\n",
    "        f['unique_lengths_'+str(l)] = lengths[l]\n",
    "        \n",
    "    return f\n",
    "\n",
    "\n",
    "def filter_by_length(events, minimum_payload=200, ratio_app_not_satisfing_minimum_payload_length=0.25, printInfo = False):\n",
    "    results = copy.deepcopy(events)\n",
    "    for watch in events:\n",
    "        for app in events[watch]:\n",
    "            for action in events[watch][app]:\n",
    "                total_event = len(events[watch][app][action])\n",
    "                bellow_minimum_payload = 0\n",
    "                for sample in events[watch][app][action]:\n",
    "\n",
    "                    payload_length = sum([abs(s) for s in sample[\"ys\"]])\n",
    "                    if payload_length < minimum_payload:\n",
    "                        bellow_minimum_payload += 1\n",
    "\n",
    "                ratio_bellow = bellow_minimum_payload / total_event\n",
    "                if ratio_bellow > ratio_app_not_satisfing_minimum_payload_length:\n",
    "                    if printInfo:\n",
    "                        print(\"total_event: \", total_event, \" - bellow threshold: \", bellow_minimum_payload)\n",
    "                        print(app + \"_\" + action + \" removed\")\n",
    "                        print(\" ratio_below = \", ratio_bellow)\n",
    "                    del results[watch][app][action]\n",
    "\n",
    "            if len(results[watch][app]) == 0:\n",
    "                del results[watch][app]\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def count_print(events):\n",
    "    for d in events:\n",
    "        for app in events[d]:\n",
    "            for act in events[d][app]:\n",
    "                print(\"{}: {}_{} - {}\".format(d, app, act,  len(events[d][app][act])))\n",
    "\n",
    "                \n",
    "# Compute the mean over realisations\n",
    "def plot_acc_and_conf(n_samples, accuracies, repeat, title, xlabel, ylabel, fname, y_lim=None, RETURN_ACC=False, dpi=500):\n",
    "    n_samples = np.array(n_samples)\n",
    "    accuracies = np.array(accuracies)\n",
    "\n",
    "\n",
    "    n_samples_repr = n_samples.reshape((-1,repeat))[:,0]\n",
    "    accuracies_repr = accuracies.reshape((-1,repeat)) * 100\n",
    "\n",
    "    accuracies_avg = accuracies.reshape((-1,repeat)).mean(axis = 1)\n",
    "    if RETURN_ACC:\n",
    "        return n_samples_repr, accuracies_avg\n",
    "    \n",
    "    accuracies_conf = accuracies.reshape((-1,repeat)).std(axis = 1) * 2 \n",
    "\n",
    "    conf_upper = accuracies_avg + accuracies_conf\n",
    "    conf_lower = accuracies_avg - accuracies_conf\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(n_samples_repr, accuracies_avg, '-b', label='averaged accuracy')\n",
    "    ax.plot(n_samples_repr, conf_upper, '--r', label='95% confidence interval')\n",
    "    ax.plot(n_samples_repr, conf_lower, '--r')\n",
    "    plt.title(title)\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    if y_lim is not None:\n",
    "        plt.ylim(y_lim[0], y_lim[1])\n",
    "    leg = ax.legend()\n",
    "    plt.savefig(\"./\"+fname, dpi=dpi)\n",
    "\n",
    "    \n",
    "    \n",
    "def extract_features(xy, capture_duration_does_nothing=0, unique_from=46, unique_to=1006): # dataset is {'xs': [packet1, packet2,...], 'ys': [packet1, packet2,...]} where x is time and y is size\n",
    "    xs = xy['xs']\n",
    "    ys = xy['ys']\n",
    "    f = dict()\n",
    "\n",
    "    def take(arr, n=30):\n",
    "        if len(arr) > n:\n",
    "            return arr[:30]\n",
    "        return arr\n",
    "\n",
    "    def stats(key, data):\n",
    "        if len(data) == 0:\n",
    "            data=[-1]\n",
    "        f['min_'+key] = np.min(data)\n",
    "        f['mean_'+key] = np.mean(data)\n",
    "        f['max_'+key] = np.max(data)\n",
    "        f['count_'+key] = len(data)\n",
    "        f['std_'+key] = np.std(data)\n",
    "        f['kurtosis_'+key] = kurtosis(data)\n",
    "\n",
    "\n",
    "\n",
    "    # general statistics\n",
    "    stats(\"non_null\", [abs(y) for y in ys if y != 0])\n",
    "    stats(\"outgoing\", [abs(y) for y in ys if y > 0])\n",
    "    stats(\"incoming\", [abs(y) for y in ys if y < 0])\n",
    "    stats(\"outgoing_30\", [abs(y) for y in take(ys) if y > 0])\n",
    "    stats(\"incoming_30\", [abs(y) for y in take(ys) if y < 0])\n",
    "\n",
    "    # f[\"total_payload\"] = sum([abs(y) for y in ys])\n",
    "\n",
    "    # statistics about timings\n",
    "    x_deltas = []\n",
    "    i = 1\n",
    "    while i<len(xs):\n",
    "        x_deltas.append(xs[i]-xs[i-1])\n",
    "        i += 1\n",
    "\n",
    "    stats(\"x_deltas\", x_deltas)\n",
    "    stats(\"x_deltas_30\", take(x_deltas))\n",
    "\n",
    "    # bursts\n",
    "\n",
    "    # unique packet lengths [Liberatore and Levine; Herrmann et al.]\n",
    "    lengths = dict()\n",
    "    for i in range(unique_from, unique_to):\n",
    "        lengths[str(i)] = 0\n",
    "    for y in ys:\n",
    "        if str(abs(y)) in lengths:\n",
    "            lengths[str(abs(y))] += 1\n",
    "\n",
    "    lengths_array = list(lengths.values())\n",
    "    stats(\"unique_lengths\", lengths_array)\n",
    "    for l in lengths:\n",
    "        f['unique_lengths_'+str(l)] = lengths[l]\n",
    "        \n",
    "    return f\n",
    "\n",
    "def get_all_actions(events):\n",
    "    all_actions = set()\n",
    "    for d in events:\n",
    "        for app in events[d]:\n",
    "            for act in events[d][app]:\n",
    "                all_actions.add(app+\"_\"+act)\n",
    "    return all_actions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"evaluate\"></a>\n",
    "### Evaluate\n",
    "[Table of Content](#tc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(DATA_PATH, DISCARDED_ACTION=[], TO_MERGE=[], EQUALIZATION=True,\n",
    "             REBUILD=False, TEST_PERCENTAGE=0.25, MINIMUM_PAYLOAD=200, SHUFFLE=False,\n",
    "             RATIO=0.25, N_SPLITS=50, N_ESTIMATOR=100, SEPARATE_WATCH=False,\n",
    "             PRINT_COUNT=False, PLOT_DIR=\"./plots/\", RETURN_PRED=False, RETURN_FILTIRED=False,\n",
    "             RETURN_EQUILIBRATE_EVENTS=False, RETURN_FEATURES_AND_LABELS=False):\n",
    "    \n",
    "    print(\"\\nimporting data...\")\n",
    "    sources_files = find_sources(DATA_PATH)\n",
    "\n",
    "\n",
    "    if len(DISCARDED_ACTION) != 0:\n",
    "        print(\"withdraw action to be discarded\")\n",
    "        sources_files = discard_actions(sources_files, DISCARDED_ACTION)\n",
    "\n",
    "\n",
    "    if REBUILD:\n",
    "        print(\"rebuilding dataset\")\n",
    "        rebuild_all_datasets(sources_files)\n",
    "\n",
    "    events, counts = cut_all_datasets_in_events(sources_files)\n",
    "\n",
    "    if len(TO_MERGE) != 0:\n",
    "        print(\"merging events\")\n",
    "        events = merge_actions_in_app(events, TO_MERGE)\n",
    "\n",
    "\n",
    "    print(\"filtering app that does not send traffic by their length\")\n",
    "    filtered_events = filter_by_length(events, minimum_payload=MINIMUM_PAYLOAD, ratio_app_not_satisfing_minimum_payload_length=RATIO)\n",
    "    \n",
    "    if RETURN_FILTIRED:\n",
    "        return filtered_events\n",
    "    \n",
    "    if PRINT_COUNT:\n",
    "        print(\"\\nclass event count\")\n",
    "        count_print(filtered_events)\n",
    "        print()\n",
    "\n",
    "    nb_samples_per_cat = \"not uniform\"\n",
    "    if EQUALIZATION:\n",
    "        print(\"dataset equalization per class\")\n",
    "        filtered_events, nb_samples_per_cat = equilibrate_events_across_apps_and_watch(filtered_events)\n",
    "        \n",
    "        if PRINT_COUNT:\n",
    "            print(\"\\nclass event count after equalization\")\n",
    "            count_print(filtered_events)\n",
    "            print()\n",
    "        if RETURN_EQUILIBRATE_EVENTS:\n",
    "            return filtered_events\n",
    "    \n",
    "    if SEPARATE_WATCH:\n",
    "        print(\"separate watch action\")\n",
    "        filtered_events = separate_watch(filtered_events)\n",
    "        if PRINT_COUNT:\n",
    "            print()\n",
    "            count_print(filtered_events)\n",
    "\n",
    "\n",
    "    print(\"building features and labels\")\n",
    "    X, y = build_features_labels_dataset(filtered_events)\n",
    "    if RETURN_FEATURES_AND_LABELS:\n",
    "        return X, y\n",
    "\n",
    "    # ## Accuracy with cross validation\n",
    "\n",
    "    print(\"building and training the model for cross validation \")\n",
    "    clf=RandomForestClassifier(n_estimators=N_ESTIMATOR, random_state=None)\n",
    "    shuf_split = ShuffleSplit(n_splits=N_SPLITS, test_size=0.25, random_state=None)\n",
    "    scores_shuffle = cross_val_score(clf, X, y, cv=shuf_split)\n",
    "    print(\"Random split cross-validation: Accuracy=%0.3f (+/- %0.2f). \" % (scores_shuffle.mean(), scores_shuffle.std() * 2))\n",
    "    eval_metric = \"cross-val radomSplit={} accRs={:.1f} +-{:.1f}% 95% conf interval\".format(N_SPLITS, scores_shuffle.mean() *100, scores_shuffle.std() * 2 * 100)\n",
    "\n",
    "    # ### Plotting the confusion matrix\n",
    "\n",
    "    print(\"building and training a model for confusion matrix\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.25, random_state=None)\n",
    "\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    if RETURN_PRED:\n",
    "        return y_test, y_pred\n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"accuracy = \", accuracy)\n",
    "\n",
    "\n",
    "    title = \"Confusion matrix for {}acc={:0.2f} \".format(\"and \".join([f.replace(\"/\", \"_\") for f in DATA_PATH]), accuracy * 100)\n",
    "    title += eval_metric\n",
    "    title += \"test={}% minimum_payload={}B nb_samples={}\".format(int(TEST_PERCENTAGE * 100), MINIMUM_PAYLOAD, nb_samples_per_cat)\n",
    "    saved_title = title.replace(\".\", \"_\").replace(\" \", \"_\")\n",
    "    cm, _, _ = plot_confusion_matrix(y_test, y_pred, title= title, save = saved_title, PLOT_DIR=PLOT_DIR)\n",
    "\n",
    "    print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='build-per-action-capture-model'></a>\n",
    "## Preparation\n",
    "\n",
    "### Build per action capture model\n",
    "[Table of Content](#tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "importing data...\n",
      "filtering app that does not send traffic by their length\n",
      "dataset equalization per class\n",
      "building features and labels\n",
      "\n",
      "importing data...\n",
      "filtering app that does not send traffic by their length\n"
     ]
    }
   ],
   "source": [
    "# Choose the data to be included in the model\n",
    "DATA_PATH = [\"data/huawei/Endomondo-1/\", \"data/huawei/force-stop/\", \"data/huawei/DiabetesM-2/\",\n",
    "             \"data/huawei/DiabetesM-3/\", \"data/huawei/DiabetesM-4/\",\n",
    "             \"data/huawei/FoursquareCityGuide-1/\", \"data/huawei/HealthyRecipes-1/\",\n",
    "             \"data/huawei/Lifesum-1/\", \"data/huawei/Playstore-1/\", \"data/huawei/open-6/\"]\n",
    "\n",
    "# Extract features \n",
    "X, y = evaluate(DATA_PATH, RETURN_FEATURES_AND_LABELS=True)\n",
    "\n",
    "# Create and Train the model\n",
    "clf=RandomForestClassifier(n_estimators=200, random_state=None)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Get the set of all classes the classifier knows about\n",
    "events = evaluate(DATA_PATH, RETURN_FILTIRED=True)\n",
    "all_actions = get_all_actions(events)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='convert-longrun'></a>\n",
    "### Import data, ground-truth and checked ground-truth\n",
    "[Table of Content](#tc)\n",
    "\n",
    "\n",
    "- ***Data*** refers to the actual longrun captures \n",
    "\n",
    "- ***Ground-truth*** refers to the metadata that comes automatically with the longrun capture. It is a log file and contains information about which and when an action is performed since the capture's launch\n",
    "\n",
    "- ***Checked ground-truth*** refers to the manually checked ground-thruth. (Used to measure the discrepancy of the automation vs the manual checked. This discrepency is due to a delay between sending the command to performing an action and the actual traffic generated by this action).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_out_path(fs, filter_out_device = False):\n",
    "    f = fs[fs.rfind('/')+ 1:]\n",
    "    if filter_out_device:\n",
    "        f = f[f.rfind('_')+ 1:]\n",
    "    return f\n",
    "\n",
    "# Finds datasets recursively\n",
    "def find_sources(folders='./'):\n",
    "\n",
    "    if type(folders) is not list:\n",
    "        folders = [folders]\n",
    "\n",
    "    sources_files = []\n",
    "\n",
    "    for folder in folders:\n",
    "        files = glob.glob(folder + '*.csv', recursive=True)\n",
    "        for file in files:\n",
    "            ignore = False\n",
    "            for ignore_pattern in SOURCES_FILE_IGNORE:\n",
    "                if ignore_pattern in file:\n",
    "                    ignore = True\n",
    "            if not ignore:\n",
    "                sources_files.append(file.replace('./', ''))\n",
    "\n",
    "    return sorted(sources_files)\n",
    "\n",
    "def extract_fname(f):\n",
    "    return filter_out_path(f[:f.rfind(\".\")])\n",
    "\n",
    "def intersection_fname(files1, files2, print_missing=True):\n",
    "    \"Return the list of files names (without extension) that files1 containes and files2 contains\"\n",
    "    if len(files1) == 0 or len(files2) == 0:\n",
    "        print(\"WARNING: one or both dir. are empty\")\n",
    "        return []\n",
    "\n",
    "    extension1 = files1[0][files1[0].rfind(\".\"):]\n",
    "    extension2 = files2[0][files2[0].rfind(\".\"):]\n",
    "\n",
    "    files1_filtered = set()\n",
    "    files2_filtered = set()\n",
    "    \n",
    "    for f1 in files1:\n",
    "        files1_filtered.add(extract_fname(f1))\n",
    "    for f2 in files2:\n",
    "        files2_filtered.add(extract_fname(f2))\n",
    "    \n",
    "    complete_files = files1_filtered.intersection(files2_filtered)\n",
    "    missing_files = sorted(list(files1_filtered.union(files2_filtered) - complete_files))\n",
    "\n",
    "    # print Missing files\n",
    "    if print_missing:\n",
    "        for mf in missing_files:\n",
    "            if mf in files1_filtered:\n",
    "                print(\"WARNING: {} - {} companion missing\".format(mf, extension2))\n",
    "            if mf in files2_filtered:\n",
    "                print(\"WARNING: {} - {} companion missing\".format(mf, extension1))\n",
    "    return sorted(list(complete_files))\n",
    "\n",
    "DATA_PATH = \"./data/huawei/longrun/\"\n",
    "GROUND_TRUTH_PATH = \"./data/huawei/longrun/ground-truth/\"\n",
    "CHECKED_GT = \"./data/huawei/longrun/checked-gt/\"\n",
    "\n",
    "data_path_content = glob.glob(DATA_PATH + '*.csv', recursive=True)\n",
    "gt_path_content = glob.glob(GROUND_TRUTH_PATH + '*.log', recursive=True)\n",
    "checked_gt_path_content = glob.glob(CHECKED_GT + '*.log', recursive=True)  \n",
    "\n",
    "\n",
    "# All data that can be used must have their .log companion (in ground-truth)\n",
    "ready_dataset = intersection_fname(data_path_content, gt_path_content)\n",
    "# All checkeds that can be used must have their .log companion (in ground-truth)\n",
    "checked_files = intersection_fname([f + \".log\" for f in ready_dataset], checked_gt_path_content, print_missing=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build ground_truth\n",
    "#### Estimating delay between groundtruth and csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_longrun_log_file(longrunLogFile, all_action=None):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        longrunLogFile : File log name (including path)\n",
    "        all_action : actions used to train the model (needed to filter out actions not part of the training set)\n",
    "    \n",
    "    Return\n",
    "        [[time, action],] : filtered and clean version of the content of a logfile\n",
    "    \"\"\"\n",
    "    out = []\n",
    "    with open(longrunLogFile, \"r\") as file:\n",
    "        csv_reader = csv.reader(file, delimiter=',', skipinitialspace=True)\n",
    "        next(csv_reader)\n",
    "        for i, line in enumerate(csv_reader):\n",
    "            if all_action is None or line[1] in all_action:\n",
    "                out.append(line)\n",
    "    return out\n",
    "            \n",
    "def read_longrun_log_files(longrunLogFiles, all_action=None):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "        longrunLogFiles : a list of files log names (including path)\n",
    "        all_action : actions used to train the model (needed to filter out actions not part of the training set)\n",
    "    \n",
    "    Return\n",
    "        dict[filename] = [[time, action],] : filtered and clean version of the content of multiple logfile\n",
    "    \"\"\"\n",
    "    out = dict()\n",
    "    for longrunLogFile in longrunLogFiles:\n",
    "        out[extract_fname(longrunLogFile)] = read_longrun_log_file(longrunLogFile, all_action)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path_files_data = [DATA_PATH + f + \".log\" for f in checked_files]\n",
    "path_files_ground_truth = [GROUND_TRUTH_PATH + f + \".log\" for f in checked_files]\n",
    "path_files_checked = [CHECKED_GT + f + \".log\" for f in checked_files]\n",
    "\n",
    "content_checked = read_longrun_log_files(path_files_checked, all_actions)\n",
    "content_ground_truth = read_longrun_log_files(path_files_ground_truth, all_actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrepency between automate and manually checked gournd-truth for action launch time differece:\n",
      "\n",
      "   mean_diff = 5.078723404255315\n",
      "   max_diff=16.5\n",
      "   min_diff=0.39999999999997726\n",
      "\n",
      " adapting correct new bound with lower = -4.600000000000023, upper = 21.5\n"
     ]
    }
   ],
   "source": [
    "def record_diff_checked_gt(checkeds, gts, all_actions):\n",
    "    recordings = []\n",
    "    for checked, gt in zip(checkeds, gts):\n",
    "        action = gt[1]\n",
    "        if action is None:\n",
    "            print(\"ERROR: Parsing failure\")\n",
    "            break\n",
    "        if eval(checked[0]) is None or action not in all_actions:\n",
    "            continue\n",
    "\n",
    "        recordings.append(float(checked[0]) - float(gt[0]))  # add the difference between \n",
    "    return recordings\n",
    "\n",
    "\n",
    "recordings = []\n",
    "\n",
    "for capt in content_checked:\n",
    "    checkeds = content_checked[capt]\n",
    "    gts = content_ground_truth[capt]\n",
    "    recordings += record_diff_checked_gt(checkeds, gts, all_actions)\n",
    "rec = np.array(recordings)\n",
    "\n",
    "print(\"Discrepency between automate and manually checked gournd-truth for action launch time differece:\\n\")\n",
    "print(\"   mean_diff = {}\\n   max_diff={}\\n   min_diff={}\\n\".format(np.mean(rec), np.max(rec), np.min(rec)))\n",
    "margin_timing_difference = 5\n",
    "upper = np.max(np.array(recordings)) + margin_timing_difference\n",
    "lower =  np.min(np.array(recordings)) - margin_timing_difference\n",
    "print(\" adapting correct new bound with lower = {}, upper = {}\".format(lower, upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_bound_for_timing_in_action(content_ground_truth, lower, upper):\n",
    "    content_ground_truth_with_bound = dict()\n",
    "    for gt in content_ground_truth:\n",
    "        new_gt = []\n",
    "        for i, action in content_ground_truth[gt]:\n",
    "            lower_bound = float(i) - lower\n",
    "            upper_bound = float(i) + upper\n",
    "            new_gt.append((lower_bound, upper_bound, action))\n",
    "        content_ground_truth_with_bound[gt] = new_gt\n",
    "    return content_ground_truth_with_bound\n",
    "bounded_gt = make_bound_for_timing_in_action(content_ground_truth, lower, upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_critical_point(time_serie):\n",
    "    # find Critcal points: where we have more than 2k data\n",
    "    ts = pd.Series(data = time_serie['ys'], index = pd.to_timedelta(time_serie[\"xs\"], 'sec'))\n",
    "\n",
    "    # filter out packets with no payload length and (or not) the ones that contains < 26 bits\n",
    "    ts = ts.map(abs)[ts != 0] #[ts > 26]\n",
    "\n",
    "    def time_delta_to_float(td):\n",
    "        if len(td) == 0:\n",
    "            return None\n",
    "        return float(str(td[0].seconds) +\".\" + str(td[0].microseconds))\n",
    "\n",
    "    # Compute the moving average of 30 seconds head in data PayloadLength\n",
    "\n",
    "    stw = ts[::-1].rolling(\"20s\").sum()[::-1]\n",
    "    stw = stw[stw > 200]  # filter out minimum 200B payload (banned app)\n",
    "\n",
    "\n",
    "    stw = stw.resample('5s').apply(lambda x: x.index) # 5 seconds jump\n",
    "    critical_points = stw.map(time_delta_to_float).dropna().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='stw'></a>\n",
    "## Sliding Time Window\n",
    "[table of content](#tc)\n",
    "\n",
    "Adventage: does not need supervision for the data\n",
    "\n",
    "Idea to improve: Take the noApp noAcction > 200KB and train a model to predict noise\n",
    "\n",
    "Preprocessing: Remove\n",
    "for each 5\n",
    "\n",
    "\n",
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_critical_point(time_serie):\n",
    "    # find Critcal points: where we have more than 2k data\n",
    "    ts = pd.Series(data = time_serie['ys'], index = pd.to_timedelta(time_serie[\"xs\"], 'sec'))\n",
    "\n",
    "    # filter out packets with no payload length and (or not) the ones that contains < 26 bits\n",
    "    ts = ts.map(abs)[ts != 0] #[ts > 26]\n",
    "\n",
    "    def time_delta_to_float(td):\n",
    "        if len(td) == 0:\n",
    "            return None\n",
    "        return float(str(td[0].seconds) +\".\" + str(td[0].microseconds))\n",
    "\n",
    "    # Compute the moving average of 30 seconds head in data PayloadLength\n",
    "\n",
    "    stw = ts[::-1].rolling(\"20s\").sum()[::-1]\n",
    "    stw = stw[stw > 200]  # filter out minimum 200B payload (banned app)\n",
    "\n",
    "\n",
    "    stw = stw.resample('5s').apply(lambda x: x.index) # 5 seconds jump\n",
    "    critical_points = stw.map(time_delta_to_float).dropna().values\n",
    "    return critical_points\n",
    "\n",
    "\n",
    "\n",
    "def find_action_end(xs_capt, ys_capt, FILTER_LENGTH_LIMIT=46 ,INTER_TIMER_EVENT_CUTOFF=5):\n",
    "    \"\"\"\n",
    "    return the potential end of the action that begins at indicce j\n",
    "    xs_capt : time elements\n",
    "    ys_capt : length elements\n",
    "    FILTER_LENGTH_LIMIT : do not take length <= n\n",
    "    INTER_TIMER_EVENT_CUTOFF ; Do not take into accout \n",
    "    \n",
    "    return indices of the en\n",
    "    \"\"\"\n",
    "    xs_no_zeros = [x  for y, x in zip(ys_capt, xs_capt) if abs(y) > FILTER_LENGTH_LIMIT]\n",
    "    for i, x0 in enumerate(xs_no_zeros):\n",
    "        if i + 1 == len(xs_no_zeros):\n",
    "            return xs_capt[-1]  # reached the end\n",
    "        x1 = xs_no_zeros[i + 1]\n",
    "        inter_time = x1-x0\n",
    "        if inter_time > INTER_TIMER_EVENT_CUTOFF:\n",
    "            return x0\n",
    "        \n",
    "def find_x_indices(xs_capt, j, xs_end):\n",
    "    for i, x in enumerate(xs_capt[j:]):\n",
    "        if xs_end == x:\n",
    "            return i + j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importation\n",
    "<a id='stw'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data importation\n",
    "<a id='stw'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "longrunCaptFile = \"./data/huawei/longrun/longrun_deterministic_20-04-03_02-42-49.csv\"\n",
    "gt_f = \"./data/huawei/longrun/ground-truth/longrun_deterministic_20-04-03_02-42-49.log\"\n",
    "gt = read_longrun_log_file(gt_f, all_actions)\n",
    "columns = extract_columns(longrunCaptFile)\n",
    "packets = read_file(longrunCaptFile, columns)\n",
    "packets = packet_store_cleanup(packets)\n",
    "time_serie = packets_to_timesize_tuples(packets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='implementation_stw'></a>\n",
    "## Implementation\n",
    "[Table of Content](#tc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(time_serie):\n",
    "    critical_points = find_critical_point(time_serie)\n",
    "\n",
    "    predicted = []  # tuple list of \n",
    "    critical_points_i = 0\n",
    "    xs_end = -1\n",
    "    xs_capt = time_serie[\"xs\"]\n",
    "    ys_capt = time_serie[\"ys\"]\n",
    "\n",
    "\n",
    "\n",
    "    for i, _ in enumerate(xs_capt):\n",
    "\n",
    "\n",
    "        current_xs = xs_capt[i]\n",
    "        critical_point = critical_points[critical_points_i]\n",
    "        if current_xs > critical_point and current_xs > xs_end:\n",
    "\n",
    "            j = i-1   # take previous one since we are one step further\n",
    "\n",
    "            xs_start = xs_capt[i]\n",
    "            xs_end = find_action_end(xs_capt[i:], ys_capt[i:])\n",
    "            end_indice = find_x_indices(xs_capt, j, xs_end)\n",
    "\n",
    "            xy = dict()\n",
    "            xy[\"xs\"] = xs_capt[j:end_indice+1]\n",
    "            xy[\"ys\"] = ys_capt[j:end_indice+1]\n",
    "            features_dict = extract_features(xy)\n",
    "            features = list(features_dict.values())\n",
    "            y = clf.predict(np.array(features).reshape(1,-1))\n",
    "            predicted.append([(xs_start, xs_end), y[0]])\n",
    "\n",
    "            while critical_points[critical_points_i] < xs_end:\n",
    "                critical_points_i +=1\n",
    "                if critical_points_i == len(critical_points):\n",
    "                    break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if critical_points_i == len(critical_points) or xs_end == xs_capt[-1]:\n",
    "            break\n",
    "    return predicted\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict(time_serie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(1.313026125, 10.322386125), 'Weather_open'],\n",
       " [(12.19614175, 21.391772375), 'FindMyPhone_force-stop'],\n",
       " [(29.812393, 83.39616325), 'Telegram_open'],\n",
       " [(86.81304725, 225.608403625), 'SalatTime_open'],\n",
       " [(227.812159375, 307.5632935), 'MapMyRun_open'],\n",
       " [(312.563294, 390.593146625), 'SalatTime_open'],\n",
       " [(392.367528625, 473.099256625), 'SalatTime_open'],\n",
       " [(473.690508375, 480.773634), 'Shazam_open'],\n",
       " [(482.794890375, 555.719751375), 'Outlook_open'],\n",
       " [(558.561630625, 641.428986), 'Translate_open'],\n",
       " [(662.8127055, 720.886352125), 'MapMyRun_open'],\n",
       " [(722.830107875, 828.318111875), 'Running_open'],\n",
       " [(834.56123725, 886.053658125), 'Lifesum_open'],\n",
       " [(887.976164, 920.0617835), 'Maps_force-stop']]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "evaluation_stw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(58.10000000000002, 75.0, 'Telegram_open'),\n",
       " (86.40000000000002, 103.3, 'Telegram_force-stop'),\n",
       " (141.90000000000003, 158.8, 'FitWorkout_open'),\n",
       " (225.00000000000003, 241.9, 'SalatTime_open'),\n",
       " (307.5, 324.4, 'MapMyRun_open'),\n",
       " (390.3, 407.2, 'SalatTime_open'),\n",
       " (472.8, 489.7, 'Shazam_open'),\n",
       " (554.8000000000001, 571.7, 'Outlook_open'),\n",
       " (638.0, 654.9, 'Translate_open'),\n",
       " (665.8000000000001, 682.7, 'Translate_force-stop'),\n",
       " (720.6, 737.5, 'MapMyRun_open'),\n",
       " (803.3000000000001, 820.2, 'Running_open'),\n",
       " (831.2, 848.1, 'Running_force-stop'),\n",
       " (886.0, 902.9, 'Lifesum_open'),\n",
       " (892.5, 909.4, 'Lifesum_addWater'),\n",
       " (917.8000000000001, 934.7, 'Lifesum_force-stop')]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounded_gt['longrun_deterministic_20-04-03_02-42-49']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(bounded_gt['longrun_deterministic_20-04-03_02-42-49']))\n",
    "print(len(predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlaps(a, b):\n",
    "    return not (b[0] > a[1] or a[0] > b[1])\n",
    "\n",
    "def compute_eval_metric_v1(prediciton, ground_truth, print_details=True):\n",
    "    \"\"\"\n",
    "    calculate accuarcy, precision and recall \n",
    "    Args:\n",
    "        prediction : [(start, stop, action),] list of predicition with time boundaries\n",
    "        ground_truth : [(start, stop, action),] list of ground_turh associated with the prediction\n",
    "        \n",
    "    Return (tp, fp, fn) True Positive, False Positive and False Negative\n",
    "    \"\"\"\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    i_pred, i_gt = 0, 0\n",
    "    correct_pred, wrong_pred, missed_pred = [], [], []\n",
    "    last_run = False\n",
    "\n",
    "    while True:\n",
    "        # Make sure indices are not overflowing\n",
    "        i_pred_m = min(i_pred, len(prediciton) - 1)\n",
    "        i_gt_m = min(i_gt, len(ground_truth) - 1)\n",
    "        \n",
    "        start_pred, stop_pred = prediciton[i_pred_m][0], prediciton[i_pred_m][1]\n",
    "        action_pred = prediciton[i_pred_m][2]\n",
    "\n",
    "        start_gt, stop_gt = ground_truth[i_gt_m][0], ground_truth[i_gt_m][1]\n",
    "        action_gt = ground_truth[i_gt_m][2]\n",
    "        \n",
    "        if print_details:\n",
    "            print(\"\\nChecking : \\npred: \", action_pred, \"\\n gt : \", action_gt)\n",
    "\n",
    "        if overlaps((start_pred, stop_pred), (start_gt, stop_gt)) and action_gt == action_pred:\n",
    "            i_pred += 1\n",
    "            i_gt += 1\n",
    "            tp += 1\n",
    "            correct_pred.append(action_gt)\n",
    "            if print_details:\n",
    "                print(action_gt + \" correct (tp + 1 = \", tp,\")\")\n",
    "\n",
    "        \n",
    "        elif stop_pred > stop_gt and i_gt != len(ground_truth):\n",
    "            i_gt += 1\n",
    "            fn += 1\n",
    "            missed_pred.append(action_gt)\n",
    "            if print_details:\n",
    "                print(action_gt, \" missed prediction (fn + 1= \", fn,\")\")\n",
    "            \n",
    "        elif stop_gt > stop_pred and i_pred != len(prediciton):\n",
    "            i_pred += 1\n",
    "            fp += 1\n",
    "            wrong_pred.append(action_pred)\n",
    "            if print_details:\n",
    "                print(action_pred + \" wrong prediction (fp + 1= \", fp, \")\")\n",
    "        else:\n",
    "            print(\"HELP\")\n",
    "            sys.exit(1)\n",
    "\n",
    "        if i_pred >= len(prediciton) - 1 and i_gt >= len(ground_truth) -1:\n",
    "            break\n",
    "        \n",
    "    print(i_pred, i_gt)\n",
    "\n",
    "\n",
    "    return correct_pred, wrong_pred, missed_pred\n",
    "\n",
    "\n",
    "def compute_eval_metric_v2(prediciton, ground_truth, print_details=True):\n",
    "    \"\"\"\n",
    "    calculate accuarcy, precision and recall \n",
    "    Args:\n",
    "        prediction : [(start, stop, action),] list of predicition with time boundaries\n",
    "        ground_truth : [(start, stop, action),] list of ground_turh associated with the prediction\n",
    "        \n",
    "    Return (tp, fp, fn) True Positive, False Positive and False Negative\n",
    "    \"\"\"\n",
    "    tp, fp, fn = 0, 0, 0\n",
    "    i_pred, i_gt = 0, 0\n",
    "    correct_pred, wrong_pred, missed_gt, correct_gt = [], [], [], []\n",
    "    last_run = False\n",
    "    \n",
    "    \n",
    "    def add_wrong_pred(pred, fp):\n",
    "        fp += 1\n",
    "        wrong_pred.append(pred)\n",
    "        if print_details:\n",
    "            print(pred[2] + \" wrong prediction (fp + 1= \", fp, \")\")\n",
    "        return fp\n",
    "            \n",
    "    def add_missed_gt(gt, fn):\n",
    "        fn += 1\n",
    "        missed_gt.append(gt)\n",
    "        if print_details:\n",
    "            print(gt[2], \" missed prediction (fn + 1= \", fn,\")\")\n",
    "        return fn\n",
    "            \n",
    "    def add_correct_pred(pred, tp):\n",
    "        tp += 1\n",
    "        correct_pred.append(pred)\n",
    "        if print_details:\n",
    "            print(pred[2] + \" correct pref (tp + 1 = \", tp,\")\")\n",
    "        return tp\n",
    "    \n",
    "    def add_correct_gt(gt):\n",
    "        correct_gt.append(gt)\n",
    "        if print_details:\n",
    "            print(gt[2], \" correct gt\")\n",
    "        return fn\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "    for gt in ground_truth:\n",
    "        start_gt, stop_gt, action_gt = gt\n",
    "        \n",
    "        matched = []\n",
    "        for pred in prediciton:\n",
    "            start_pred, stop_pred, action_pred = pred\n",
    "            \n",
    "                \n",
    "            # we found a match\n",
    "            if overlaps((start_pred, stop_pred), (start_gt, stop_gt)) and action_gt == action_pred:\n",
    "                if pred not in correct_pred and gt not in correct_gt:\n",
    "                    tp = add_correct_pred(pred, tp)\n",
    "                    add_correct_gt(gt)\n",
    "                    break\n",
    "        \n",
    "        if gt not in correct_gt:\n",
    "            fn = add_missed_gt(gt, fn)\n",
    "    \n",
    "    # compute wrong pred:\n",
    "    for pred in prediciton:        \n",
    "        if pred not in correct_pred:\n",
    "            fp = add_wrong_pred(pred, fp)\n",
    "\n",
    "    return correct_pred, wrong_pred, missed_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = [(1.313026125, 10.322386125, 'Translate_open'),\n",
    " (12.19614175, 21.391772375, 'FindMyPhone_force-stop'),\n",
    " (29.812393, 83.39616325, 'Telegram_open'),\n",
    " (86.81304725, 225.608403625, 'SalatTime_open'),\n",
    " (227.812159375, 307.5632935, 'MapMyRun_open'),\n",
    " (312.563294, 390.593146625, 'SalatTime_open'),\n",
    " (392.367528625, 473.099256625, 'SalatTime_open'),\n",
    " (473.690508375, 480.773634, 'Shazam_open'),\n",
    " (482.794890375, 555.719751375, 'Outlook_open'),\n",
    " (558.561630625, 641.428986, 'Translate_open'),\n",
    " (662.8127055, 720.886352125, 'MapMyRun_open'),\n",
    " (722.830107875, 828.318111875, 'Running_open'),\n",
    " (834.56123725, 886.053658125, 'Lifesum_open'),\n",
    " (887.976164, 920.0617835, 'Maps_force-stop')] \n",
    "\n",
    "bounded_gt_test = [(58.10000000000002, 75.0, 'Telegram_open'),\n",
    " (86.40000000000002, 103.3, 'Telegram_force-stop'),\n",
    " (141.90000000000003, 158.8, 'FitWorkout_open'),\n",
    " (225.00000000000003, 241.9, 'SalatTime_open'),\n",
    " (307.5, 324.4, 'MapMyRun_open'),\n",
    " (390.3, 407.2, 'SalatTime_open'),\n",
    " (472.8, 489.7, 'Shazam_open'),\n",
    " (554.8000000000001, 571.7, 'Outlook_open'),\n",
    " (638.0, 654.9, 'Translate_open'),\n",
    " (665.8000000000001, 682.7, 'Translate_force-stop'),\n",
    " (720.6, 737.5, 'MapMyRun_open'),\n",
    " (803.3000000000001, 820.2, 'Running_open'),\n",
    " (831.2, 848.1, 'Running_force-stop'),\n",
    " (886.0, 902.9, 'Lifesum_open')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29.812393, 83.39616325, 'Telegram_open'),\n",
       " (86.81304725, 225.608403625, 'SalatTime_open'),\n",
       " (227.812159375, 307.5632935, 'MapMyRun_open'),\n",
       " (312.563294, 390.593146625, 'SalatTime_open'),\n",
       " (473.690508375, 480.773634, 'Shazam_open'),\n",
       " (482.794890375, 555.719751375, 'Outlook_open'),\n",
       " (558.561630625, 641.428986, 'Translate_open'),\n",
       " (662.8127055, 720.886352125, 'MapMyRun_open'),\n",
       " (722.830107875, 828.318111875, 'Running_open'),\n",
       " (834.56123725, 886.053658125, 'Lifesum_open')]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.313026125, 10.322386125, 'Translate_open'),\n",
       " (12.19614175, 21.391772375, 'FindMyPhone_force-stop'),\n",
       " (392.367528625, 473.099256625, 'SalatTime_open'),\n",
       " (887.976164, 920.0617835, 'Maps_force-stop')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Telegram_open 58.10 - 75.00\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Telegram_open 58.10 - 75.00\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Telegram_open 58.10 - 75.00\n",
      "Telegram_open correct pref (tp + 1 =  1 )\n",
      "Telegram_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 558.56 - 641.43\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 662.81 - 720.89\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: Running_open 722.83 - 828.32\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: Lifesum_open 834.56 - 886.05\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "\n",
      "Checking : \n",
      "pred: Maps_force-stop 887.98 - 920.06\n",
      "gt:   Telegram_force-stop 86.40 - 103.30\n",
      "Telegram_force-stop  missed prediction (fn + 1=  1 )\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 558.56 - 641.43\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 662.81 - 720.89\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: Running_open 722.83 - 828.32\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: Lifesum_open 834.56 - 886.05\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "\n",
      "Checking : \n",
      "pred: Maps_force-stop 887.98 - 920.06\n",
      "gt:   FitWorkout_open 141.90 - 158.80\n",
      "FitWorkout_open  missed prediction (fn + 1=  2 )\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   SalatTime_open 225.00 - 241.90\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   SalatTime_open 225.00 - 241.90\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   SalatTime_open 225.00 - 241.90\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   SalatTime_open 225.00 - 241.90\n",
      "SalatTime_open correct pref (tp + 1 =  2 )\n",
      "SalatTime_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   MapMyRun_open 307.50 - 324.40\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   MapMyRun_open 307.50 - 324.40\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   MapMyRun_open 307.50 - 324.40\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   MapMyRun_open 307.50 - 324.40\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   MapMyRun_open 307.50 - 324.40\n",
      "MapMyRun_open correct pref (tp + 1 =  3 )\n",
      "MapMyRun_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   SalatTime_open 390.30 - 407.20\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   SalatTime_open 390.30 - 407.20\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   SalatTime_open 390.30 - 407.20\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   SalatTime_open 390.30 - 407.20\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   SalatTime_open 390.30 - 407.20\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   SalatTime_open 390.30 - 407.20\n",
      "SalatTime_open correct pref (tp + 1 =  4 )\n",
      "SalatTime_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Shazam_open 472.80 - 489.70\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Shazam_open 472.80 - 489.70\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Shazam_open 472.80 - 489.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   Shazam_open 472.80 - 489.70\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   Shazam_open 472.80 - 489.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   Shazam_open 472.80 - 489.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   Shazam_open 472.80 - 489.70\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   Shazam_open 472.80 - 489.70\n",
      "Shazam_open correct pref (tp + 1 =  5 )\n",
      "Shazam_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   Outlook_open 554.80 - 571.70\n",
      "Outlook_open correct pref (tp + 1 =  6 )\n",
      "Outlook_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 558.56 - 641.43\n",
      "gt:   Translate_open 638.00 - 654.90\n",
      "Translate_open correct pref (tp + 1 =  7 )\n",
      "Translate_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 558.56 - 641.43\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 662.81 - 720.89\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: Running_open 722.83 - 828.32\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: Lifesum_open 834.56 - 886.05\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "\n",
      "Checking : \n",
      "pred: Maps_force-stop 887.98 - 920.06\n",
      "gt:   Translate_force-stop 665.80 - 682.70\n",
      "Translate_force-stop  missed prediction (fn + 1=  3 )\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 558.56 - 641.43\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 662.81 - 720.89\n",
      "gt:   MapMyRun_open 720.60 - 737.50\n",
      "MapMyRun_open correct pref (tp + 1 =  8 )\n",
      "MapMyRun_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 558.56 - 641.43\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 662.81 - 720.89\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "\n",
      "Checking : \n",
      "pred: Running_open 722.83 - 828.32\n",
      "gt:   Running_open 803.30 - 820.20\n",
      "Running_open correct pref (tp + 1 =  9 )\n",
      "Running_open  correct gt\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 558.56 - 641.43\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 662.81 - 720.89\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: Running_open 722.83 - 828.32\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: Lifesum_open 834.56 - 886.05\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "\n",
      "Checking : \n",
      "pred: Maps_force-stop 887.98 - 920.06\n",
      "gt:   Running_force-stop 831.20 - 848.10\n",
      "Running_force-stop  missed prediction (fn + 1=  4 )\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 1.31 - 10.32\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: FindMyPhone_force-stop 12.20 - 21.39\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: Telegram_open 29.81 - 83.40\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 86.81 - 225.61\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 227.81 - 307.56\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 312.56 - 390.59\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: SalatTime_open 392.37 - 473.10\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: Shazam_open 473.69 - 480.77\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: Outlook_open 482.79 - 555.72\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: Translate_open 558.56 - 641.43\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: MapMyRun_open 662.81 - 720.89\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: Running_open 722.83 - 828.32\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "\n",
      "Checking : \n",
      "pred: Lifesum_open 834.56 - 886.05\n",
      "gt:   Lifesum_open 886.00 - 902.90\n",
      "Lifesum_open correct pref (tp + 1 =  10 )\n",
      "Lifesum_open  correct gt\n",
      "Translate_open wrong prediction (fp + 1=  1 )\n",
      "FindMyPhone_force-stop wrong prediction (fp + 1=  2 )\n",
      "SalatTime_open wrong prediction (fp + 1=  3 )\n",
      "Maps_force-stop wrong prediction (fp + 1=  4 )\n",
      "precision = 0.7142857142857143, recall = 0.43478260869565216\n",
      "tp = 10, fp = 4, fn = 13\n"
     ]
    }
   ],
   "source": [
    "(correct_pred, wrong_pred, missed_pred) = compute_eval_metric_v2(pred_test , bounded_gt_test, print_details=True)\n",
    "tp, fp, fn = len(correct_pred), len(wrong_pred), len(missed_pred)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"precision = {}, recall = {}\".format(precision, recall))\n",
    "print(\"tp = {}, fp = {}, fn = {}\".format(tp,fp,fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-0d3dfc9c421b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mcorrect_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrong_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissed_pred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_eval_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mbounded_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'longrun_deterministic_20-04-03_02-42-49'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_details\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrong_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissed_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-ec5a099eebaf>\u001b[0m in \u001b[0;36mcompute_eval_metric\u001b[0;34m(prediciton, ground_truth, print_details)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mstart_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediciton\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_pred_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediciton\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_pred_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0maction_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprediciton\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_pred_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mstart_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop_gt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_gt_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi_gt_m\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "(correct_pred, wrong_pred, missed_pred) = compute_eval_metric(predicted , bounded_gt['longrun_deterministic_20-04-03_02-42-49'], print_details=True)\n",
    "\n",
    "tp, fp, fn = len(correct_pred), len(wrong_pred), len(missed_pred)\n",
    "\n",
    "precision = tp / (tp + fp)\n",
    "recall = tp / (tp + fn)\n",
    "print(\"precision = {}, recall = {}\".format(precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_predb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation metrics: \n",
    "\n",
    "***Precision*** :\n",
    "   The Precision can be computed by the following formula:\n",
    "   $$\\frac{TP}{TP + FP}$$\n",
    "   \n",
    "   where:\n",
    "\n",
    "       TP: stands for True Positive. The number of correct prediction\n",
    "       FP: stands for False Positive. The number of wrong prediction (either because of the timing or because of the label )\n",
    "       FN: stands for False Negative. The number true_label (in the ground_truth) not found out\n",
    " \n",
    "***Recall***:\n",
    "    The Precision can be computed by the following formula:\n",
    "    $$\\frac{TP}{TP + FN}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp + fp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp + fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
